{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osamaoun97/MovieLens_Recommender_System/blob/model_training/notebooks/Multi_task_Recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfaK4bgJwoHD"
      },
      "source": [
        "# Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK2nPnXRwqLV"
      },
      "source": [
        "This notebook is used to train a multi-task matrix factorization model for recommendation.<br>\n",
        "We'll consider the both implicit interaction and explicit rating in the MovieLens100k dataset.<br>\n",
        "We'll use tensorflow recommenders to achieve this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA00wBE2Ntdm"
      },
      "source": [
        "## Import TFRS\n",
        "\n",
        "First, install and import TFRS and needed packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yzAaM85Z12D",
        "outputId": "3a2f3bc6-1bf1-4ae2-8cd5-c397b010998b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/96.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q tensorflow_recommenders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n3oYt3R6Nr9l"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, Text\n",
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "from urllib.request import urlretrieve\n",
        "from zipfile import ZipFile\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IXyCV5VaijJg"
      },
      "outputs": [],
      "source": [
        "SEED = 19011"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXbl9WKn3h6z",
        "outputId": "8fc58228-da87-4228-f788-986e6a26b5c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.12.0', 'v0.7.3')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# python version: 3.10.11\n",
        "tf.__version__, tfrs.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCxQ1CZcO2wh"
      },
      "source": [
        "## Download and extract data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5RAQ5D8necP_"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = 'data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RuiYFhuAeaet"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(DATA_DIR):\n",
        "  os.mkdir(DATA_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mTzAph9diHSX"
      },
      "outputs": [],
      "source": [
        "compressed_file_URL = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "compressed_filename = compressed_file_URL.split('/')[-1] # ml-latest-small.zip\n",
        "extracted_filename = compressed_filename.split('.')[0] # ml-latest-small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZGCLfOKWc8J6"
      },
      "outputs": [],
      "source": [
        "compressed_file_path = os.path.join(DATA_DIR, compressed_filename) # data/ml-latest-small.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRn7FC5aiFAn",
        "outputId": "29960358-860f-4393-edd3-5551a2546747"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('data/ml-latest-small.zip', <http.client.HTTPMessage at 0x7fbaec289ab0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "urlretrieve(compressed_file_URL, compressed_file_path) # Download file form url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aP-nR2qSibUZ"
      },
      "outputs": [],
      "source": [
        "with ZipFile(compressed_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(path=DATA_DIR) # extract file to data/\n",
        "os.remove(compressed_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhM4W1t6keqc"
      },
      "source": [
        "## Load, prepare and split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Zbd_qpKVf0ub"
      },
      "outputs": [],
      "source": [
        "file_path = os.path.join(DATA_DIR, extracted_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RmZbNGNqOtv-"
      },
      "outputs": [],
      "source": [
        "ratings = pd.read_csv(file_path + '/ratings.csv')\n",
        "movies = pd.read_csv(file_path + '/movies.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QPZtsEu4PVfE",
        "outputId": "f43183ce-15c6-4cb9-e12b-b5c43b48461a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       1        1     4.0  964982703\n",
              "1       1        3     4.0  964981247\n",
              "2       1        6     4.0  964982224\n",
              "3       1       47     5.0  964983815\n",
              "4       1       50     5.0  964982931"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac5096a6-b276-47a1-9d2b-df83dd6baa53\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac5096a6-b276-47a1-9d2b-df83dd6baa53')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac5096a6-b276-47a1-9d2b-df83dd6baa53 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac5096a6-b276-47a1-9d2b-df83dd6baa53');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "ratings.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDmrB9PFk7Qj",
        "outputId": "0b7bc478-ec3a-437d-f143-aa4791348e6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100836 entries, 0 to 100835\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count   Dtype  \n",
            "---  ------     --------------   -----  \n",
            " 0   userId     100836 non-null  int64  \n",
            " 1   movieId    100836 non-null  int64  \n",
            " 2   rating     100836 non-null  float64\n",
            " 3   timestamp  100836 non-null  int64  \n",
            "dtypes: float64(1), int64(3)\n",
            "memory usage: 3.1 MB\n"
          ]
        }
      ],
      "source": [
        "ratings.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "H-kSygb2k-DM",
        "outputId": "0272fd83-1e5a-476f-fb30-fb2cf3a25ed4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   movieId                               title  \\\n",
              "0        1                    Toy Story (1995)   \n",
              "1        2                      Jumanji (1995)   \n",
              "2        3             Grumpier Old Men (1995)   \n",
              "3        4            Waiting to Exhale (1995)   \n",
              "4        5  Father of the Bride Part II (1995)   \n",
              "\n",
              "                                        genres  \n",
              "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
              "1                   Adventure|Children|Fantasy  \n",
              "2                               Comedy|Romance  \n",
              "3                         Comedy|Drama|Romance  \n",
              "4                                       Comedy  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55b153de-ee10-45b2-b7f9-057efdec3702\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55b153de-ee10-45b2-b7f9-057efdec3702')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55b153de-ee10-45b2-b7f9-057efdec3702 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55b153de-ee10-45b2-b7f9-057efdec3702');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "movies.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYMFHFE0k_0G",
        "outputId": "eba159ad-e2b9-43c7-fdf0-7ded7559924a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9742 entries, 0 to 9741\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   movieId  9742 non-null   int64 \n",
            " 1   title    9742 non-null   object\n",
            " 2   genres   9742 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 228.5+ KB\n"
          ]
        }
      ],
      "source": [
        "movies.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "-tw-BoVHP06x",
        "outputId": "12040652-c535-4f5d-c6bd-61ceb0bed521"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        userId                      movieTitle  rating   timestamp\n",
              "0            1                  Jumanji (1995)     4.0   964982703\n",
              "516          5                  Jumanji (1995)     4.0   847434962\n",
              "874          7                  Jumanji (1995)     4.5  1106635946\n",
              "1434        15                  Jumanji (1995)     2.5  1510577970\n",
              "1667        17                  Jumanji (1995)     4.5  1305696483\n",
              "...        ...                             ...     ...         ...\n",
              "99945      610  Mrs. Henderson Presents (2005)     3.5  1479542444\n",
              "100012     610                Planet 51 (2009)     3.0  1493848602\n",
              "100033     610              Source Code (2011)     2.5  1479544865\n",
              "100038     610              Master, The (2012)     4.0  1495959169\n",
              "100060     610                  Breathe (2014)     1.0  1479542247\n",
              "\n",
              "[77939 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68cbbdcc-a3ea-4c86-a938-3592651d8221\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieTitle</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>5</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>4.0</td>\n",
              "      <td>847434962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>874</th>\n",
              "      <td>7</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1106635946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1434</th>\n",
              "      <td>15</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1510577970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1667</th>\n",
              "      <td>17</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1305696483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99945</th>\n",
              "      <td>610</td>\n",
              "      <td>Mrs. Henderson Presents (2005)</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1479542444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100012</th>\n",
              "      <td>610</td>\n",
              "      <td>Planet 51 (2009)</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1493848602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100033</th>\n",
              "      <td>610</td>\n",
              "      <td>Source Code (2011)</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1479544865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100038</th>\n",
              "      <td>610</td>\n",
              "      <td>Master, The (2012)</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1495959169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100060</th>\n",
              "      <td>610</td>\n",
              "      <td>Breathe (2014)</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1479542247</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>77939 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68cbbdcc-a3ea-4c86-a938-3592651d8221')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68cbbdcc-a3ea-4c86-a938-3592651d8221 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68cbbdcc-a3ea-4c86-a938-3592651d8221');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "ratings = ratings.join(movies, on='movieId', lsuffix='', rsuffix='_', how='inner')[['userId', 'title', 'rating', 'timestamp']].rename(columns={'title':'movieTitle'})\n",
        "ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "7KiLC-gIRU7K",
        "outputId": "138c4c6f-60c8-4f2a-ca59-405dbbc1ef8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      movieId                                 movieTitle  \\\n",
              "0           1                           Toy Story (1995)   \n",
              "1           2                             Jumanji (1995)   \n",
              "2           3                    Grumpier Old Men (1995)   \n",
              "3           4                   Waiting to Exhale (1995)   \n",
              "4           5         Father of the Bride Part II (1995)   \n",
              "...       ...                                        ...   \n",
              "9737   193581  Black Butler: Book of the Atlantic (2017)   \n",
              "9738   193583               No Game No Life: Zero (2017)   \n",
              "9739   193585                               Flint (2017)   \n",
              "9740   193587        Bungo Stray Dogs: Dead Apple (2018)   \n",
              "9741   193609        Andrew Dice Clay: Dice Rules (1991)   \n",
              "\n",
              "                                           genres  \n",
              "0     Adventure|Animation|Children|Comedy|Fantasy  \n",
              "1                      Adventure|Children|Fantasy  \n",
              "2                                  Comedy|Romance  \n",
              "3                            Comedy|Drama|Romance  \n",
              "4                                          Comedy  \n",
              "...                                           ...  \n",
              "9737              Action|Animation|Comedy|Fantasy  \n",
              "9738                     Animation|Comedy|Fantasy  \n",
              "9739                                        Drama  \n",
              "9740                             Action|Animation  \n",
              "9741                                       Comedy  \n",
              "\n",
              "[9742 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4095ceeb-0446-4f7f-a5b2-cb9e0f1b4ba0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>movieTitle</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9737</th>\n",
              "      <td>193581</td>\n",
              "      <td>Black Butler: Book of the Atlantic (2017)</td>\n",
              "      <td>Action|Animation|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9738</th>\n",
              "      <td>193583</td>\n",
              "      <td>No Game No Life: Zero (2017)</td>\n",
              "      <td>Animation|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9739</th>\n",
              "      <td>193585</td>\n",
              "      <td>Flint (2017)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9740</th>\n",
              "      <td>193587</td>\n",
              "      <td>Bungo Stray Dogs: Dead Apple (2018)</td>\n",
              "      <td>Action|Animation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9741</th>\n",
              "      <td>193609</td>\n",
              "      <td>Andrew Dice Clay: Dice Rules (1991)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9742 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4095ceeb-0446-4f7f-a5b2-cb9e0f1b4ba0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4095ceeb-0446-4f7f-a5b2-cb9e0f1b4ba0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4095ceeb-0446-4f7f-a5b2-cb9e0f1b4ba0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "movies = movies.rename(columns={'title':'movieTitle'})\n",
        "movies"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll convert ids from int to string so that they can be processed by tf StringLookup layer."
      ],
      "metadata": {
        "id": "mcqkzhw3yBqH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TFn8P4_Ms72Z"
      },
      "outputs": [],
      "source": [
        "ratings['userId'] = ratings['userId'].map(lambda id_int: str(id_int))\n",
        "movies['movieId'] = movies['movieId'].map(lambda id_int: str(id_int))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qPviRgX_ppSf"
      },
      "outputs": [],
      "source": [
        "train_valid , test = train_test_split(ratings, test_size=0.2, stratify=ratings['userId'], random_state=SEED)\n",
        "train, valid = train_test_split(train_valid, test_size=0.1, stratify=train_valid['userId'], random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DB9IZmxIzHVR"
      },
      "outputs": [],
      "source": [
        "# Keep only interactions of movies seen in training data\n",
        "valid = valid[valid['movieTitle'].isin(train['movieTitle'].unique())]\n",
        "test = test[test['movieTitle'].isin(train_valid['movieTitle'].unique())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBNQTcET_0UH",
        "outputId": "b1bd7752-7a95-4d87-eeba-9f7da34aa84e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((56115, 4), (6095, 4), (15248, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "train.shape, valid.shape, test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X58OruuYFt2s"
      },
      "source": [
        "## Data Prepatation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll create a tensorflow dataset for the train, validation and test sets. This will make it easier for modelling.\n",
        "\n",
        "Each element in the dataset is a dictionary that has the following key:\n",
        "- userId: This is the id of the user for which we make recommendation. It is an input feature\n",
        "- movieTitle: This is the title of the movie.\n",
        "- rating: This is the rating the user gave to the movie. It is our target label."
      ],
      "metadata": {
        "id": "mh6u6efcyVYK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuiVqj_vFOU1",
        "outputId": "5d53bf95-41e2-4abe-e856-6cc027fa42fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec={'userId': TensorSpec(shape=(), dtype=tf.string, name=None), 'movieTitle': TensorSpec(shape=(), dtype=tf.string, name=None), 'rating': TensorSpec(shape=(), dtype=tf.float64, name=None)}>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "train_rating_dataset = tf.data.Dataset.from_tensor_slices({'userId':train['userId'].values, 'movieTitle': train['movieTitle'].values, 'rating': train['rating'].values})\n",
        "valid_rating_dataset = tf.data.Dataset.from_tensor_slices({'userId':valid['userId'].values, 'movieTitle': valid['movieTitle'].values, 'rating': valid['rating'].values})\n",
        "test_rating_dataset = tf.data.Dataset.from_tensor_slices({'userId':test['userId'].values, 'movieTitle': test['movieTitle'].values, 'rating': test['rating'].values})\n",
        "train_rating_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "sRXBt0o011nA"
      },
      "outputs": [],
      "source": [
        "movie_dataset = tf.data.Dataset.from_tensor_slices(train['movieTitle'].unique())\n",
        "user_dataset = tf.data.Dataset.from_tensor_slices(train['userId'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wRnkJTnouAnc"
      },
      "outputs": [],
      "source": [
        "user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None, name='users_lookup', num_oov_indices=0)\n",
        "movie_titles_vocabulary = tf.keras.layers.StringLookup(mask_token=None, name='movies_lookup', num_oov_indices=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "NHskzAhwuGsJ"
      },
      "outputs": [],
      "source": [
        "user_ids_vocabulary.adapt(user_dataset.map(lambda x: x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "UEQj2OyYMpjI"
      },
      "outputs": [],
      "source": [
        "movie_titles_vocabulary.adapt(movie_dataset.map(lambda x: x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f3JfPbAvu9X",
        "outputId": "eed34ff7-df19-456a-cadd-784502206a86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(610, 4960)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "n_users = user_ids_vocabulary.vocabulary_size()\n",
        "n_movies = movie_titles_vocabulary.vocabulary_size()\n",
        "n_users, n_movies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lesKfVayFvli"
      },
      "source": [
        "## Define model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model has three components:\n",
        "- user_model: This converts the userId to a dense vector representing the user's preferences.\n",
        "- movie_model: This converts the movieTitle to a dense vector representing the movie's characteristics.\n",
        "-rating_model: This is a module that takes the output of the user_model and movie_model and generates prediction for this user's rating of this movie."
      ],
      "metadata": {
        "id": "n5J5Scm6zFCd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model has two tasks (each task has a loss and metrics):\n",
        "- Ranking task: This task ranks each candidate by estimating the rating the user would give. It has a regression loss that is calculated between the predicted rating and the true rating. The loss is usually mean squared error and the metric is root mean squared error.\n",
        "- Retrieval task: This task generated candidates for a user from all available movies in our dataset. It has a classification as the output can be one of defined set of movies. The loss is Crossentropy and the metric is topk accuracy.\n",
        "\n",
        "\n",
        "Note: Top k accuracy (for example k=10) means how often our target variable (which is a movie in our case) appears in the top k of candidates generated by the model.\n"
      ],
      "metadata": {
        "id": "OGpUyDq0zuWp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ShsW910MF4Qy"
      },
      "outputs": [],
      "source": [
        "class MultitaskRecommender(tfrs.Model):\n",
        "  def __init__(self, embedding_dimension=32, rating_weight: float=1., retrieval_weight: float =1.) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    # Set up user and movie representations.\n",
        "    self.movie_model = tf.keras.Sequential(\n",
        "        [\n",
        "          movie_titles_vocabulary,\n",
        "          tf.keras.layers.Embedding(n_movies, embedding_dimension, name='movie_embedding')\n",
        "        ],\n",
        "        name='movie_model')\n",
        "\n",
        "    self.user_model = tf.keras.Sequential(\n",
        "        [\n",
        "          user_ids_vocabulary,\n",
        "          tf.keras.layers.Embedding(n_users, embedding_dimension, name='user_embedding')\n",
        "        ],\n",
        "        name='user_model')\n",
        "\n",
        "    # Set up MLP to predict rating from user and movie representation\n",
        "    self.rating_model = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.Dense(256, activation='relu'),\n",
        "            tf.keras.layers.Dense(128,  activation='relu'),\n",
        "            tf.keras.layers.Dense(1)\n",
        "        ],\n",
        "        name='rating_model')\n",
        "\n",
        "    # Set up ranking and retrieval tasks\n",
        "    self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
        "          loss=tf.keras.losses.MeanSquaredError(name='MSE'),\n",
        "          metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
        "      )\n",
        "\n",
        "    self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
        "        metrics=tfrs.metrics.FactorizedTopK(\n",
        "            candidates=movie_dataset.batch(128).map(self.movie_model),\n",
        "            ks = (5,10)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Set up weights for rating task and retrieval task\n",
        "    self.rating_weight = rating_weight\n",
        "    self.retrieval_weight = retrieval_weight\n",
        "\n",
        "  def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
        "    # We pick out the user features and pass them into the user model.\n",
        "    user_embeddings = self.user_model(features[\"userId\"])\n",
        "    # And pick out the movie features and pass them into the movie model.\n",
        "    movie_embeddings = self.movie_model(features[\"movieTitle\"])\n",
        "\n",
        "    return (\n",
        "        user_embeddings,\n",
        "        movie_embeddings,\n",
        "        # We apply the multi-layered rating model to a concatentation of\n",
        "        # user and movie embeddings.\n",
        "        self.rating_model(\n",
        "            tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
        "        ),\n",
        "    )\n",
        "\n",
        "  def compute_loss(self, features_label: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "\n",
        "    ratings = features_label.pop(\"rating\")\n",
        "\n",
        "    user_embeddings, movie_embeddings, rating_predictions = self(features_label)\n",
        "\n",
        "    # We compute the loss for each task.\n",
        "    rating_loss = self.rating_task(labels=ratings, predictions=rating_predictions)\n",
        "    retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
        "\n",
        "    # And combine them using the loss weights.\n",
        "    return self.rating_weight*rating_loss + self.retrieval_weight*retrieval_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRZRPVE7AChW"
      },
      "source": [
        "## Compile and fit"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's cache the training dataset first. We'll use batch size of 8192"
      ],
      "metadata": {
        "id": "CkF3_XX41eDw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "LEARSKx-nR2N"
      },
      "outputs": [],
      "source": [
        "cached_train = train_rating_dataset.shuffle(100_000).batch(8192).cache()\n",
        "cached_valid = train_rating_dataset.shuffle(100_000).batch(4096).cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NvAFiYIN0DC"
      },
      "source": [
        "### Trial 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "emh1VJG3p72v"
      },
      "outputs": [],
      "source": [
        "# This function keeps the initial learning rate for the first ten epochs\n",
        "# and decreases it exponentially after that.\n",
        "def scheduler(epoch, lr):\n",
        "  return lr * tf.math.exp(-0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Fbw7_TETLy2w"
      },
      "outputs": [],
      "source": [
        "multi_model = MultitaskRecommender(embedding_dimension=32, rating_weight=1., retrieval_weight=1)\n",
        "multi_model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.01))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3wvyygHTte6",
        "outputId": "a86abceb-44e9-4e05-fe29-30b41ce1776a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 25s 3s/step - RMSE: 3.3846 - factorized_top_k/top_5_categorical_accuracy: 6.4154e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0017 - loss: 70777.8691 - regularization_loss: 0.0000e+00 - total_loss: 70777.8691 - val_RMSE: 2.9417 - val_factorized_top_k/top_5_categorical_accuracy: 0.0017 - val_factorized_top_k/top_10_categorical_accuracy: 0.0037 - val_loss: 22829.9141 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22829.9141 - lr: 0.0095\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 14s 2s/step - RMSE: 2.5581 - factorized_top_k/top_5_categorical_accuracy: 0.0017 - factorized_top_k/top_10_categorical_accuracy: 0.0038 - loss: 70762.4512 - regularization_loss: 0.0000e+00 - total_loss: 70762.4512 - val_RMSE: 1.9444 - val_factorized_top_k/top_5_categorical_accuracy: 0.0049 - val_factorized_top_k/top_10_categorical_accuracy: 0.0090 - val_loss: 22820.7070 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22820.7070 - lr: 0.0090\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 13s 2s/step - RMSE: 1.6009 - factorized_top_k/top_5_categorical_accuracy: 0.0050 - factorized_top_k/top_10_categorical_accuracy: 0.0097 - loss: 70744.0303 - regularization_loss: 0.0000e+00 - total_loss: 70744.0303 - val_RMSE: 1.2148 - val_factorized_top_k/top_5_categorical_accuracy: 0.0121 - val_factorized_top_k/top_10_categorical_accuracy: 0.0215 - val_loss: 22811.4121 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22811.4121 - lr: 0.0086\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.1277 - factorized_top_k/top_5_categorical_accuracy: 0.0105 - factorized_top_k/top_10_categorical_accuracy: 0.0204 - loss: 70720.1104 - regularization_loss: 0.0000e+00 - total_loss: 70720.1104 - val_RMSE: 1.0660 - val_factorized_top_k/top_5_categorical_accuracy: 0.0198 - val_factorized_top_k/top_10_categorical_accuracy: 0.0348 - val_loss: 22800.5586 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22800.5586 - lr: 0.0082\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0582 - factorized_top_k/top_5_categorical_accuracy: 0.0146 - factorized_top_k/top_10_categorical_accuracy: 0.0296 - loss: 70687.6104 - regularization_loss: 0.0000e+00 - total_loss: 70687.6104 - val_RMSE: 1.0515 - val_factorized_top_k/top_5_categorical_accuracy: 0.0237 - val_factorized_top_k/top_10_categorical_accuracy: 0.0424 - val_loss: 22786.4629 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22786.4629 - lr: 0.0078\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0486 - factorized_top_k/top_5_categorical_accuracy: 0.0170 - factorized_top_k/top_10_categorical_accuracy: 0.0355 - loss: 70646.3516 - regularization_loss: 0.0000e+00 - total_loss: 70646.3516 - val_RMSE: 1.0443 - val_factorized_top_k/top_5_categorical_accuracy: 0.0257 - val_factorized_top_k/top_10_categorical_accuracy: 0.0467 - val_loss: 22769.4766 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22769.4766 - lr: 0.0074\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0413 - factorized_top_k/top_5_categorical_accuracy: 0.0186 - factorized_top_k/top_10_categorical_accuracy: 0.0385 - loss: 70598.3301 - regularization_loss: 0.0000e+00 - total_loss: 70598.3301 - val_RMSE: 1.0369 - val_factorized_top_k/top_5_categorical_accuracy: 0.0266 - val_factorized_top_k/top_10_categorical_accuracy: 0.0482 - val_loss: 22750.5059 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22750.5059 - lr: 0.0070\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0341 - factorized_top_k/top_5_categorical_accuracy: 0.0197 - factorized_top_k/top_10_categorical_accuracy: 0.0401 - loss: 70546.0166 - regularization_loss: 0.0000e+00 - total_loss: 70546.0166 - val_RMSE: 1.0302 - val_factorized_top_k/top_5_categorical_accuracy: 0.0267 - val_factorized_top_k/top_10_categorical_accuracy: 0.0492 - val_loss: 22730.4512 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22730.4512 - lr: 0.0067\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0280 - factorized_top_k/top_5_categorical_accuracy: 0.0206 - factorized_top_k/top_10_categorical_accuracy: 0.0411 - loss: 70491.6318 - regularization_loss: 0.0000e+00 - total_loss: 70491.6318 - val_RMSE: 1.0249 - val_factorized_top_k/top_5_categorical_accuracy: 0.0265 - val_factorized_top_k/top_10_categorical_accuracy: 0.0495 - val_loss: 22710.0391 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22710.0391 - lr: 0.0064\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0233 - factorized_top_k/top_5_categorical_accuracy: 0.0205 - factorized_top_k/top_10_categorical_accuracy: 0.0419 - loss: 70436.9014 - regularization_loss: 0.0000e+00 - total_loss: 70436.9014 - val_RMSE: 1.0211 - val_factorized_top_k/top_5_categorical_accuracy: 0.0264 - val_factorized_top_k/top_10_categorical_accuracy: 0.0495 - val_loss: 22689.8047 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22689.8047 - lr: 0.0061\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbaec937ee0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "multi_model.fit(cached_train, epochs=10, validation_data=cached_valid, callbacks=[tf.keras.callbacks.LearningRateScheduler(scheduler)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G-oyTjDqvRo",
        "outputId": "e3e7663f-dd30-4c7e-ce05-3b4a91f4774b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0200 - factorized_top_k/top_5_categorical_accuracy: 0.0204 - factorized_top_k/top_10_categorical_accuracy: 0.0424 - loss: 70383.0449 - regularization_loss: 0.0000e+00 - total_loss: 70383.0449 - val_RMSE: 1.0184 - val_factorized_top_k/top_5_categorical_accuracy: 0.0264 - val_factorized_top_k/top_10_categorical_accuracy: 0.0491 - val_loss: 22670.1172 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22670.1172 - lr: 0.0058\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0175 - factorized_top_k/top_5_categorical_accuracy: 0.0208 - factorized_top_k/top_10_categorical_accuracy: 0.0427 - loss: 70330.8926 - regularization_loss: 0.0000e+00 - total_loss: 70330.8926 - val_RMSE: 1.0162 - val_factorized_top_k/top_5_categorical_accuracy: 0.0262 - val_factorized_top_k/top_10_categorical_accuracy: 0.0495 - val_loss: 22651.1914 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22651.1914 - lr: 0.0055\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0154 - factorized_top_k/top_5_categorical_accuracy: 0.0210 - factorized_top_k/top_10_categorical_accuracy: 0.0427 - loss: 70280.9443 - regularization_loss: 0.0000e+00 - total_loss: 70280.9443 - val_RMSE: 1.0143 - val_factorized_top_k/top_5_categorical_accuracy: 0.0261 - val_factorized_top_k/top_10_categorical_accuracy: 0.0489 - val_loss: 22633.1758 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22633.1758 - lr: 0.0052\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0136 - factorized_top_k/top_5_categorical_accuracy: 0.0212 - factorized_top_k/top_10_categorical_accuracy: 0.0428 - loss: 70233.4883 - regularization_loss: 0.0000e+00 - total_loss: 70233.4883 - val_RMSE: 1.0125 - val_factorized_top_k/top_5_categorical_accuracy: 0.0259 - val_factorized_top_k/top_10_categorical_accuracy: 0.0488 - val_loss: 22616.1309 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22616.1309 - lr: 0.0050\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 13s 2s/step - RMSE: 1.0119 - factorized_top_k/top_5_categorical_accuracy: 0.0210 - factorized_top_k/top_10_categorical_accuracy: 0.0431 - loss: 70188.6523 - regularization_loss: 0.0000e+00 - total_loss: 70188.6523 - val_RMSE: 1.0109 - val_factorized_top_k/top_5_categorical_accuracy: 0.0258 - val_factorized_top_k/top_10_categorical_accuracy: 0.0484 - val_loss: 22600.0742 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22600.0742 - lr: 0.0047\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0102 - factorized_top_k/top_5_categorical_accuracy: 0.0211 - factorized_top_k/top_10_categorical_accuracy: 0.0431 - loss: 70146.4648 - regularization_loss: 0.0000e+00 - total_loss: 70146.4648 - val_RMSE: 1.0092 - val_factorized_top_k/top_5_categorical_accuracy: 0.0257 - val_factorized_top_k/top_10_categorical_accuracy: 0.0483 - val_loss: 22585.0078 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22585.0078 - lr: 0.0045\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0086 - factorized_top_k/top_5_categorical_accuracy: 0.0212 - factorized_top_k/top_10_categorical_accuracy: 0.0435 - loss: 70106.8857 - regularization_loss: 0.0000e+00 - total_loss: 70106.8857 - val_RMSE: 1.0077 - val_factorized_top_k/top_5_categorical_accuracy: 0.0258 - val_factorized_top_k/top_10_categorical_accuracy: 0.0481 - val_loss: 22570.8945 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22570.8945 - lr: 0.0043\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0071 - factorized_top_k/top_5_categorical_accuracy: 0.0212 - factorized_top_k/top_10_categorical_accuracy: 0.0438 - loss: 70069.8340 - regularization_loss: 0.0000e+00 - total_loss: 70069.8340 - val_RMSE: 1.0062 - val_factorized_top_k/top_5_categorical_accuracy: 0.0253 - val_factorized_top_k/top_10_categorical_accuracy: 0.0482 - val_loss: 22557.7031 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22557.7031 - lr: 0.0041\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0057 - factorized_top_k/top_5_categorical_accuracy: 0.0212 - factorized_top_k/top_10_categorical_accuracy: 0.0438 - loss: 70035.1924 - regularization_loss: 0.0000e+00 - total_loss: 70035.1924 - val_RMSE: 1.0048 - val_factorized_top_k/top_5_categorical_accuracy: 0.0254 - val_factorized_top_k/top_10_categorical_accuracy: 0.0483 - val_loss: 22545.3809 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22545.3809 - lr: 0.0039\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 15s 2s/step - RMSE: 1.0043 - factorized_top_k/top_5_categorical_accuracy: 0.0213 - factorized_top_k/top_10_categorical_accuracy: 0.0439 - loss: 70002.8398 - regularization_loss: 0.0000e+00 - total_loss: 70002.8398 - val_RMSE: 1.0035 - val_factorized_top_k/top_5_categorical_accuracy: 0.0252 - val_factorized_top_k/top_10_categorical_accuracy: 0.0480 - val_loss: 22533.8828 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22533.8828 - lr: 0.0037\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fba535cd840>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "multi_model.fit(cached_train, epochs=20, validation_data=cached_valid, callbacks=[tf.keras.callbacks.LearningRateScheduler(scheduler)], initial_epoch=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWKzvcKerG2O",
        "outputId": "1cbca642-e35e-4e5a-a4fa-672879478fc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0031 - factorized_top_k/top_5_categorical_accuracy: 0.0214 - factorized_top_k/top_10_categorical_accuracy: 0.0438 - loss: 69972.6387 - regularization_loss: 0.0000e+00 - total_loss: 69972.6387 - val_RMSE: 1.0023 - val_factorized_top_k/top_5_categorical_accuracy: 0.0253 - val_factorized_top_k/top_10_categorical_accuracy: 0.0479 - val_loss: 22523.1543 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22523.1543 - lr: 0.0035\n",
            "Epoch 12/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0019 - factorized_top_k/top_5_categorical_accuracy: 0.0214 - factorized_top_k/top_10_categorical_accuracy: 0.0438 - loss: 69944.4629 - regularization_loss: 0.0000e+00 - total_loss: 69944.4629 - val_RMSE: 1.0012 - val_factorized_top_k/top_5_categorical_accuracy: 0.0254 - val_factorized_top_k/top_10_categorical_accuracy: 0.0480 - val_loss: 22513.1543 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22513.1543 - lr: 0.0033\n",
            "Epoch 13/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0008 - factorized_top_k/top_5_categorical_accuracy: 0.0213 - factorized_top_k/top_10_categorical_accuracy: 0.0439 - loss: 69918.1797 - regularization_loss: 0.0000e+00 - total_loss: 69918.1797 - val_RMSE: 1.0001 - val_factorized_top_k/top_5_categorical_accuracy: 0.0252 - val_factorized_top_k/top_10_categorical_accuracy: 0.0478 - val_loss: 22503.8223 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22503.8223 - lr: 0.0032\n",
            "Epoch 14/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9997 - factorized_top_k/top_5_categorical_accuracy: 0.0214 - factorized_top_k/top_10_categorical_accuracy: 0.0438 - loss: 69893.6660 - regularization_loss: 0.0000e+00 - total_loss: 69893.6660 - val_RMSE: 0.9991 - val_factorized_top_k/top_5_categorical_accuracy: 0.0252 - val_factorized_top_k/top_10_categorical_accuracy: 0.0474 - val_loss: 22495.1270 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22495.1270 - lr: 0.0030\n",
            "Epoch 15/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9988 - factorized_top_k/top_5_categorical_accuracy: 0.0213 - factorized_top_k/top_10_categorical_accuracy: 0.0439 - loss: 69870.7949 - regularization_loss: 0.0000e+00 - total_loss: 69870.7949 - val_RMSE: 0.9982 - val_factorized_top_k/top_5_categorical_accuracy: 0.0251 - val_factorized_top_k/top_10_categorical_accuracy: 0.0477 - val_loss: 22487.0156 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22487.0156 - lr: 0.0029\n",
            "Epoch 16/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9979 - factorized_top_k/top_5_categorical_accuracy: 0.0214 - factorized_top_k/top_10_categorical_accuracy: 0.0437 - loss: 69849.4619 - regularization_loss: 0.0000e+00 - total_loss: 69849.4619 - val_RMSE: 0.9974 - val_factorized_top_k/top_5_categorical_accuracy: 0.0251 - val_factorized_top_k/top_10_categorical_accuracy: 0.0477 - val_loss: 22479.4453 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22479.4453 - lr: 0.0027\n",
            "Epoch 17/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9971 - factorized_top_k/top_5_categorical_accuracy: 0.0213 - factorized_top_k/top_10_categorical_accuracy: 0.0437 - loss: 69829.5498 - regularization_loss: 0.0000e+00 - total_loss: 69829.5498 - val_RMSE: 0.9966 - val_factorized_top_k/top_5_categorical_accuracy: 0.0252 - val_factorized_top_k/top_10_categorical_accuracy: 0.0474 - val_loss: 22472.3848 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22472.3848 - lr: 0.0026\n",
            "Epoch 18/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9963 - factorized_top_k/top_5_categorical_accuracy: 0.0212 - factorized_top_k/top_10_categorical_accuracy: 0.0438 - loss: 69810.9697 - regularization_loss: 0.0000e+00 - total_loss: 69810.9697 - val_RMSE: 0.9959 - val_factorized_top_k/top_5_categorical_accuracy: 0.0252 - val_factorized_top_k/top_10_categorical_accuracy: 0.0477 - val_loss: 22465.7969 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22465.7969 - lr: 0.0025\n",
            "Epoch 19/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9956 - factorized_top_k/top_5_categorical_accuracy: 0.0213 - factorized_top_k/top_10_categorical_accuracy: 0.0438 - loss: 69793.6230 - regularization_loss: 0.0000e+00 - total_loss: 69793.6230 - val_RMSE: 0.9952 - val_factorized_top_k/top_5_categorical_accuracy: 0.0252 - val_factorized_top_k/top_10_categorical_accuracy: 0.0480 - val_loss: 22459.6426 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22459.6426 - lr: 0.0023\n",
            "Epoch 20/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9949 - factorized_top_k/top_5_categorical_accuracy: 0.0213 - factorized_top_k/top_10_categorical_accuracy: 0.0438 - loss: 69777.4209 - regularization_loss: 0.0000e+00 - total_loss: 69777.4209 - val_RMSE: 0.9946 - val_factorized_top_k/top_5_categorical_accuracy: 0.0250 - val_factorized_top_k/top_10_categorical_accuracy: 0.0478 - val_loss: 22453.8945 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22453.8945 - lr: 0.0022\n",
            "Epoch 21/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9943 - factorized_top_k/top_5_categorical_accuracy: 0.0213 - factorized_top_k/top_10_categorical_accuracy: 0.0439 - loss: 69762.2861 - regularization_loss: 0.0000e+00 - total_loss: 69762.2861 - val_RMSE: 0.9940 - val_factorized_top_k/top_5_categorical_accuracy: 0.0249 - val_factorized_top_k/top_10_categorical_accuracy: 0.0475 - val_loss: 22448.5293 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22448.5293 - lr: 0.0021\n",
            "Epoch 22/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9938 - factorized_top_k/top_5_categorical_accuracy: 0.0214 - factorized_top_k/top_10_categorical_accuracy: 0.0438 - loss: 69748.1436 - regularization_loss: 0.0000e+00 - total_loss: 69748.1436 - val_RMSE: 0.9934 - val_factorized_top_k/top_5_categorical_accuracy: 0.0249 - val_factorized_top_k/top_10_categorical_accuracy: 0.0474 - val_loss: 22443.5098 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22443.5098 - lr: 0.0020\n",
            "Epoch 23/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9932 - factorized_top_k/top_5_categorical_accuracy: 0.0215 - factorized_top_k/top_10_categorical_accuracy: 0.0437 - loss: 69734.9268 - regularization_loss: 0.0000e+00 - total_loss: 69734.9268 - val_RMSE: 0.9929 - val_factorized_top_k/top_5_categorical_accuracy: 0.0250 - val_factorized_top_k/top_10_categorical_accuracy: 0.0475 - val_loss: 22438.8223 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22438.8223 - lr: 0.0019\n",
            "Epoch 24/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9927 - factorized_top_k/top_5_categorical_accuracy: 0.0215 - factorized_top_k/top_10_categorical_accuracy: 0.0439 - loss: 69722.5625 - regularization_loss: 0.0000e+00 - total_loss: 69722.5625 - val_RMSE: 0.9925 - val_factorized_top_k/top_5_categorical_accuracy: 0.0249 - val_factorized_top_k/top_10_categorical_accuracy: 0.0473 - val_loss: 22434.4316 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22434.4316 - lr: 0.0018\n",
            "Epoch 25/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9923 - factorized_top_k/top_5_categorical_accuracy: 0.0214 - factorized_top_k/top_10_categorical_accuracy: 0.0439 - loss: 69711.0020 - regularization_loss: 0.0000e+00 - total_loss: 69711.0020 - val_RMSE: 0.9920 - val_factorized_top_k/top_5_categorical_accuracy: 0.0248 - val_factorized_top_k/top_10_categorical_accuracy: 0.0472 - val_loss: 22430.3301 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22430.3301 - lr: 0.0017\n",
            "Epoch 26/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9919 - factorized_top_k/top_5_categorical_accuracy: 0.0215 - factorized_top_k/top_10_categorical_accuracy: 0.0439 - loss: 69700.1797 - regularization_loss: 0.0000e+00 - total_loss: 69700.1797 - val_RMSE: 0.9916 - val_factorized_top_k/top_5_categorical_accuracy: 0.0247 - val_factorized_top_k/top_10_categorical_accuracy: 0.0473 - val_loss: 22426.4902 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22426.4902 - lr: 0.0017\n",
            "Epoch 27/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9915 - factorized_top_k/top_5_categorical_accuracy: 0.0216 - factorized_top_k/top_10_categorical_accuracy: 0.0440 - loss: 69690.0518 - regularization_loss: 0.0000e+00 - total_loss: 69690.0518 - val_RMSE: 0.9912 - val_factorized_top_k/top_5_categorical_accuracy: 0.0247 - val_factorized_top_k/top_10_categorical_accuracy: 0.0473 - val_loss: 22422.8965 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22422.8965 - lr: 0.0016\n",
            "Epoch 28/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9911 - factorized_top_k/top_5_categorical_accuracy: 0.0216 - factorized_top_k/top_10_categorical_accuracy: 0.0440 - loss: 69680.5703 - regularization_loss: 0.0000e+00 - total_loss: 69680.5703 - val_RMSE: 0.9909 - val_factorized_top_k/top_5_categorical_accuracy: 0.0248 - val_factorized_top_k/top_10_categorical_accuracy: 0.0474 - val_loss: 22419.5293 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22419.5293 - lr: 0.0015\n",
            "Epoch 29/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9907 - factorized_top_k/top_5_categorical_accuracy: 0.0217 - factorized_top_k/top_10_categorical_accuracy: 0.0440 - loss: 69671.6895 - regularization_loss: 0.0000e+00 - total_loss: 69671.6895 - val_RMSE: 0.9905 - val_factorized_top_k/top_5_categorical_accuracy: 0.0249 - val_factorized_top_k/top_10_categorical_accuracy: 0.0471 - val_loss: 22416.3770 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22416.3770 - lr: 0.0014\n",
            "Epoch 30/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9904 - factorized_top_k/top_5_categorical_accuracy: 0.0217 - factorized_top_k/top_10_categorical_accuracy: 0.0440 - loss: 69663.3652 - regularization_loss: 0.0000e+00 - total_loss: 69663.3652 - val_RMSE: 0.9902 - val_factorized_top_k/top_5_categorical_accuracy: 0.0246 - val_factorized_top_k/top_10_categorical_accuracy: 0.0473 - val_loss: 22413.4219 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22413.4219 - lr: 0.0014\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fba535fb3a0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "multi_model.fit(cached_train, epochs=30, validation_data=cached_valid, callbacks=[tf.keras.callbacks.LearningRateScheduler(scheduler)], initial_epoch=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPvOeY0KN136"
      },
      "source": [
        "### Trial 2: Higher Embedding Dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "_ESKBi1ZNoLi"
      },
      "outputs": [],
      "source": [
        "multi_model_deeper = MultitaskRecommender(embedding_dimension=64, rating_weight=1., retrieval_weight=1)\n",
        "multi_model_deeper.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.01))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUaWB6_sNrKE",
        "outputId": "1d29d2db-1d7f-4365-f5e2-39bfb0a6f44b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "7/7 [==============================] - 15s 2s/step - RMSE: 3.3734 - factorized_top_k/top_5_categorical_accuracy: 8.0192e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0019 - loss: 70777.4385 - regularization_loss: 0.0000e+00 - total_loss: 70777.4385 - val_RMSE: 2.9224 - val_factorized_top_k/top_5_categorical_accuracy: 0.0025 - val_factorized_top_k/top_10_categorical_accuracy: 0.0052 - val_loss: 22825.6855 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22825.6855 - lr: 0.0095\n",
            "Epoch 2/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 2.5272 - factorized_top_k/top_5_categorical_accuracy: 0.0029 - factorized_top_k/top_10_categorical_accuracy: 0.0059 - loss: 70748.6797 - regularization_loss: 0.0000e+00 - total_loss: 70748.6797 - val_RMSE: 1.8929 - val_factorized_top_k/top_5_categorical_accuracy: 0.0099 - val_factorized_top_k/top_10_categorical_accuracy: 0.0174 - val_loss: 22810.2246 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22810.2246 - lr: 0.0090\n",
            "Epoch 3/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.5499 - factorized_top_k/top_5_categorical_accuracy: 0.0086 - factorized_top_k/top_10_categorical_accuracy: 0.0170 - loss: 70709.1768 - regularization_loss: 0.0000e+00 - total_loss: 70709.1768 - val_RMSE: 1.1790 - val_factorized_top_k/top_5_categorical_accuracy: 0.0210 - val_factorized_top_k/top_10_categorical_accuracy: 0.0379 - val_loss: 22790.8047 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22790.8047 - lr: 0.0086\n",
            "Epoch 4/30\n",
            "7/7 [==============================] - 13s 2s/step - RMSE: 1.1050 - factorized_top_k/top_5_categorical_accuracy: 0.0141 - factorized_top_k/top_10_categorical_accuracy: 0.0299 - loss: 70653.3271 - regularization_loss: 0.0000e+00 - total_loss: 70653.3271 - val_RMSE: 1.0543 - val_factorized_top_k/top_5_categorical_accuracy: 0.0273 - val_factorized_top_k/top_10_categorical_accuracy: 0.0500 - val_loss: 22765.7227 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22765.7227 - lr: 0.0082\n",
            "Epoch 5/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0468 - factorized_top_k/top_5_categorical_accuracy: 0.0180 - factorized_top_k/top_10_categorical_accuracy: 0.0374 - loss: 70579.3809 - regularization_loss: 0.0000e+00 - total_loss: 70579.3809 - val_RMSE: 1.0387 - val_factorized_top_k/top_5_categorical_accuracy: 0.0303 - val_factorized_top_k/top_10_categorical_accuracy: 0.0563 - val_loss: 22734.5176 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22734.5176 - lr: 0.0078\n",
            "Epoch 6/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0344 - factorized_top_k/top_5_categorical_accuracy: 0.0205 - factorized_top_k/top_10_categorical_accuracy: 0.0424 - loss: 70490.8750 - regularization_loss: 0.0000e+00 - total_loss: 70490.8750 - val_RMSE: 1.0283 - val_factorized_top_k/top_5_categorical_accuracy: 0.0315 - val_factorized_top_k/top_10_categorical_accuracy: 0.0583 - val_loss: 22699.0859 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22699.0859 - lr: 0.0074\n",
            "Epoch 7/30\n",
            "7/7 [==============================] - 13s 2s/step - RMSE: 1.0248 - factorized_top_k/top_5_categorical_accuracy: 0.0223 - factorized_top_k/top_10_categorical_accuracy: 0.0456 - loss: 70393.4141 - regularization_loss: 0.0000e+00 - total_loss: 70393.4141 - val_RMSE: 1.0200 - val_factorized_top_k/top_5_categorical_accuracy: 0.0322 - val_factorized_top_k/top_10_categorical_accuracy: 0.0591 - val_loss: 22661.5312 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22661.5312 - lr: 0.0070\n",
            "Epoch 8/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0175 - factorized_top_k/top_5_categorical_accuracy: 0.0234 - factorized_top_k/top_10_categorical_accuracy: 0.0473 - loss: 70292.0518 - regularization_loss: 0.0000e+00 - total_loss: 70292.0518 - val_RMSE: 1.0141 - val_factorized_top_k/top_5_categorical_accuracy: 0.0322 - val_factorized_top_k/top_10_categorical_accuracy: 0.0590 - val_loss: 22623.4883 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22623.4883 - lr: 0.0067\n",
            "Epoch 9/30\n",
            "7/7 [==============================] - 13s 2s/step - RMSE: 1.0123 - factorized_top_k/top_5_categorical_accuracy: 0.0237 - factorized_top_k/top_10_categorical_accuracy: 0.0488 - loss: 70190.5537 - regularization_loss: 0.0000e+00 - total_loss: 70190.5537 - val_RMSE: 1.0098 - val_factorized_top_k/top_5_categorical_accuracy: 0.0321 - val_factorized_top_k/top_10_categorical_accuracy: 0.0589 - val_loss: 22586.0840 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22586.0840 - lr: 0.0064\n",
            "Epoch 10/30\n",
            "7/7 [==============================] - 13s 2s/step - RMSE: 1.0084 - factorized_top_k/top_5_categorical_accuracy: 0.0242 - factorized_top_k/top_10_categorical_accuracy: 0.0495 - loss: 70091.4385 - regularization_loss: 0.0000e+00 - total_loss: 70091.4385 - val_RMSE: 1.0063 - val_factorized_top_k/top_5_categorical_accuracy: 0.0317 - val_factorized_top_k/top_10_categorical_accuracy: 0.0585 - val_loss: 22550.0195 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22550.0195 - lr: 0.0061\n",
            "Epoch 11/30\n",
            "7/7 [==============================] - 17s 3s/step - RMSE: 1.0052 - factorized_top_k/top_5_categorical_accuracy: 0.0244 - factorized_top_k/top_10_categorical_accuracy: 0.0501 - loss: 69996.2598 - regularization_loss: 0.0000e+00 - total_loss: 69996.2598 - val_RMSE: 1.0033 - val_factorized_top_k/top_5_categorical_accuracy: 0.0313 - val_factorized_top_k/top_10_categorical_accuracy: 0.0580 - val_loss: 22515.7051 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22515.7051 - lr: 0.0058\n",
            "Epoch 12/30\n",
            "7/7 [==============================] - 13s 2s/step - RMSE: 1.0023 - factorized_top_k/top_5_categorical_accuracy: 0.0246 - factorized_top_k/top_10_categorical_accuracy: 0.0501 - loss: 69905.8799 - regularization_loss: 0.0000e+00 - total_loss: 69905.8799 - val_RMSE: 1.0007 - val_factorized_top_k/top_5_categorical_accuracy: 0.0312 - val_factorized_top_k/top_10_categorical_accuracy: 0.0575 - val_loss: 22483.3379 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22483.3379 - lr: 0.0055\n",
            "Epoch 13/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9997 - factorized_top_k/top_5_categorical_accuracy: 0.0251 - factorized_top_k/top_10_categorical_accuracy: 0.0503 - loss: 69820.7148 - regularization_loss: 0.0000e+00 - total_loss: 69820.7148 - val_RMSE: 0.9983 - val_factorized_top_k/top_5_categorical_accuracy: 0.0307 - val_factorized_top_k/top_10_categorical_accuracy: 0.0572 - val_loss: 22452.9766 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22452.9766 - lr: 0.0052\n",
            "Epoch 14/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9974 - factorized_top_k/top_5_categorical_accuracy: 0.0253 - factorized_top_k/top_10_categorical_accuracy: 0.0506 - loss: 69740.8643 - regularization_loss: 0.0000e+00 - total_loss: 69740.8643 - val_RMSE: 0.9961 - val_factorized_top_k/top_5_categorical_accuracy: 0.0309 - val_factorized_top_k/top_10_categorical_accuracy: 0.0572 - val_loss: 22424.6152 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22424.6152 - lr: 0.0050\n",
            "Epoch 15/30\n",
            "7/7 [==============================] - 13s 2s/step - RMSE: 0.9953 - factorized_top_k/top_5_categorical_accuracy: 0.0253 - factorized_top_k/top_10_categorical_accuracy: 0.0508 - loss: 69666.2676 - regularization_loss: 0.0000e+00 - total_loss: 69666.2676 - val_RMSE: 0.9942 - val_factorized_top_k/top_5_categorical_accuracy: 0.0307 - val_factorized_top_k/top_10_categorical_accuracy: 0.0564 - val_loss: 22398.1914 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22398.1914 - lr: 0.0047\n",
            "Epoch 16/30\n",
            "7/7 [==============================] - 13s 2s/step - RMSE: 0.9935 - factorized_top_k/top_5_categorical_accuracy: 0.0253 - factorized_top_k/top_10_categorical_accuracy: 0.0510 - loss: 69596.7383 - regularization_loss: 0.0000e+00 - total_loss: 69596.7383 - val_RMSE: 0.9925 - val_factorized_top_k/top_5_categorical_accuracy: 0.0311 - val_factorized_top_k/top_10_categorical_accuracy: 0.0565 - val_loss: 22373.6055 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22373.6055 - lr: 0.0045\n",
            "Epoch 17/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9919 - factorized_top_k/top_5_categorical_accuracy: 0.0253 - factorized_top_k/top_10_categorical_accuracy: 0.0506 - loss: 69532.0293 - regularization_loss: 0.0000e+00 - total_loss: 69532.0293 - val_RMSE: 0.9909 - val_factorized_top_k/top_5_categorical_accuracy: 0.0305 - val_factorized_top_k/top_10_categorical_accuracy: 0.0560 - val_loss: 22350.7578 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22350.7578 - lr: 0.0043\n",
            "Epoch 18/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9904 - factorized_top_k/top_5_categorical_accuracy: 0.0254 - factorized_top_k/top_10_categorical_accuracy: 0.0505 - loss: 69471.8594 - regularization_loss: 0.0000e+00 - total_loss: 69471.8594 - val_RMSE: 0.9896 - val_factorized_top_k/top_5_categorical_accuracy: 0.0308 - val_factorized_top_k/top_10_categorical_accuracy: 0.0558 - val_loss: 22329.5410 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22329.5410 - lr: 0.0041\n",
            "Epoch 19/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9891 - factorized_top_k/top_5_categorical_accuracy: 0.0256 - factorized_top_k/top_10_categorical_accuracy: 0.0508 - loss: 69415.9463 - regularization_loss: 0.0000e+00 - total_loss: 69415.9463 - val_RMSE: 0.9883 - val_factorized_top_k/top_5_categorical_accuracy: 0.0303 - val_factorized_top_k/top_10_categorical_accuracy: 0.0554 - val_loss: 22309.8359 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22309.8359 - lr: 0.0039\n",
            "Epoch 20/30\n",
            "7/7 [==============================] - 13s 2s/step - RMSE: 0.9879 - factorized_top_k/top_5_categorical_accuracy: 0.0256 - factorized_top_k/top_10_categorical_accuracy: 0.0510 - loss: 69363.9961 - regularization_loss: 0.0000e+00 - total_loss: 69363.9961 - val_RMSE: 0.9872 - val_factorized_top_k/top_5_categorical_accuracy: 0.0306 - val_factorized_top_k/top_10_categorical_accuracy: 0.0553 - val_loss: 22291.5410 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22291.5410 - lr: 0.0037\n",
            "Epoch 21/30\n",
            "7/7 [==============================] - 13s 2s/step - RMSE: 0.9868 - factorized_top_k/top_5_categorical_accuracy: 0.0256 - factorized_top_k/top_10_categorical_accuracy: 0.0510 - loss: 69315.7285 - regularization_loss: 0.0000e+00 - total_loss: 69315.7285 - val_RMSE: 0.9861 - val_factorized_top_k/top_5_categorical_accuracy: 0.0304 - val_factorized_top_k/top_10_categorical_accuracy: 0.0553 - val_loss: 22274.5488 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22274.5488 - lr: 0.0035\n",
            "Epoch 22/30\n",
            "7/7 [==============================] - 13s 2s/step - RMSE: 0.9858 - factorized_top_k/top_5_categorical_accuracy: 0.0258 - factorized_top_k/top_10_categorical_accuracy: 0.0511 - loss: 69270.8779 - regularization_loss: 0.0000e+00 - total_loss: 69270.8779 - val_RMSE: 0.9852 - val_factorized_top_k/top_5_categorical_accuracy: 0.0304 - val_factorized_top_k/top_10_categorical_accuracy: 0.0551 - val_loss: 22258.7598 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22258.7598 - lr: 0.0033\n",
            "Epoch 23/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9848 - factorized_top_k/top_5_categorical_accuracy: 0.0259 - factorized_top_k/top_10_categorical_accuracy: 0.0511 - loss: 69229.1885 - regularization_loss: 0.0000e+00 - total_loss: 69229.1885 - val_RMSE: 0.9843 - val_factorized_top_k/top_5_categorical_accuracy: 0.0305 - val_factorized_top_k/top_10_categorical_accuracy: 0.0548 - val_loss: 22244.0918 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22244.0918 - lr: 0.0032\n",
            "Epoch 24/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9840 - factorized_top_k/top_5_categorical_accuracy: 0.0260 - factorized_top_k/top_10_categorical_accuracy: 0.0512 - loss: 69190.4287 - regularization_loss: 0.0000e+00 - total_loss: 69190.4287 - val_RMSE: 0.9835 - val_factorized_top_k/top_5_categorical_accuracy: 0.0302 - val_factorized_top_k/top_10_categorical_accuracy: 0.0550 - val_loss: 22230.4531 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22230.4531 - lr: 0.0030\n",
            "Epoch 25/30\n",
            "7/7 [==============================] - 13s 2s/step - RMSE: 0.9832 - factorized_top_k/top_5_categorical_accuracy: 0.0261 - factorized_top_k/top_10_categorical_accuracy: 0.0513 - loss: 69154.3740 - regularization_loss: 0.0000e+00 - total_loss: 69154.3740 - val_RMSE: 0.9827 - val_factorized_top_k/top_5_categorical_accuracy: 0.0302 - val_factorized_top_k/top_10_categorical_accuracy: 0.0552 - val_loss: 22217.7656 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22217.7656 - lr: 0.0029\n",
            "Epoch 26/30\n",
            "7/7 [==============================] - 13s 2s/step - RMSE: 0.9824 - factorized_top_k/top_5_categorical_accuracy: 0.0261 - factorized_top_k/top_10_categorical_accuracy: 0.0513 - loss: 69120.8262 - regularization_loss: 0.0000e+00 - total_loss: 69120.8262 - val_RMSE: 0.9820 - val_factorized_top_k/top_5_categorical_accuracy: 0.0304 - val_factorized_top_k/top_10_categorical_accuracy: 0.0552 - val_loss: 22205.9629 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22205.9629 - lr: 0.0027\n",
            "Epoch 27/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9818 - factorized_top_k/top_5_categorical_accuracy: 0.0263 - factorized_top_k/top_10_categorical_accuracy: 0.0512 - loss: 69089.5889 - regularization_loss: 0.0000e+00 - total_loss: 69089.5889 - val_RMSE: 0.9813 - val_factorized_top_k/top_5_categorical_accuracy: 0.0301 - val_factorized_top_k/top_10_categorical_accuracy: 0.0552 - val_loss: 22194.9688 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22194.9688 - lr: 0.0026\n",
            "Epoch 28/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9811 - factorized_top_k/top_5_categorical_accuracy: 0.0264 - factorized_top_k/top_10_categorical_accuracy: 0.0514 - loss: 69060.5000 - regularization_loss: 0.0000e+00 - total_loss: 69060.5000 - val_RMSE: 0.9807 - val_factorized_top_k/top_5_categorical_accuracy: 0.0302 - val_factorized_top_k/top_10_categorical_accuracy: 0.0552 - val_loss: 22184.7324 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22184.7324 - lr: 0.0025\n",
            "Epoch 29/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9805 - factorized_top_k/top_5_categorical_accuracy: 0.0265 - factorized_top_k/top_10_categorical_accuracy: 0.0515 - loss: 69033.3896 - regularization_loss: 0.0000e+00 - total_loss: 69033.3896 - val_RMSE: 0.9801 - val_factorized_top_k/top_5_categorical_accuracy: 0.0301 - val_factorized_top_k/top_10_categorical_accuracy: 0.0550 - val_loss: 22175.1934 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22175.1934 - lr: 0.0023\n",
            "Epoch 30/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9799 - factorized_top_k/top_5_categorical_accuracy: 0.0264 - factorized_top_k/top_10_categorical_accuracy: 0.0515 - loss: 69008.1201 - regularization_loss: 0.0000e+00 - total_loss: 69008.1201 - val_RMSE: 0.9796 - val_factorized_top_k/top_5_categorical_accuracy: 0.0304 - val_factorized_top_k/top_10_categorical_accuracy: 0.0550 - val_loss: 22166.2949 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22166.2949 - lr: 0.0022\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fba535cf880>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "multi_model_deeper.fit(cached_train, epochs=30, validation_data=cached_valid, callbacks=[tf.keras.callbacks.LearningRateScheduler(scheduler)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-HG9ufLVzQI"
      },
      "source": [
        "### Trial 3: More weight for retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "bhPwWJGVV3Kq"
      },
      "outputs": [],
      "source": [
        "multi_model_retrieval = MultitaskRecommender(embedding_dimension=32, rating_weight=0.8, retrieval_weight=1)\n",
        "multi_model_retrieval.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.01))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys5X82ynV3Ky",
        "outputId": "f8a4a73f-1c78-403a-9f11-8be3ee79893a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "7/7 [==============================] - 15s 2s/step - RMSE: 3.4394 - factorized_top_k/top_5_categorical_accuracy: 8.5539e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0019 - loss: 70775.8398 - regularization_loss: 0.0000e+00 - total_loss: 70775.8398 - val_RMSE: 3.0903 - val_factorized_top_k/top_5_categorical_accuracy: 0.0021 - val_factorized_top_k/top_10_categorical_accuracy: 0.0040 - val_loss: 22828.6426 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22828.6426 - lr: 0.0095\n",
            "Epoch 2/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 2.8007 - factorized_top_k/top_5_categorical_accuracy: 0.0021 - factorized_top_k/top_10_categorical_accuracy: 0.0042 - loss: 70761.9863 - regularization_loss: 0.0000e+00 - total_loss: 70761.9863 - val_RMSE: 2.3309 - val_factorized_top_k/top_5_categorical_accuracy: 0.0050 - val_factorized_top_k/top_10_categorical_accuracy: 0.0095 - val_loss: 22820.9961 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22820.9961 - lr: 0.0090\n",
            "Epoch 3/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.9967 - factorized_top_k/top_5_categorical_accuracy: 0.0055 - factorized_top_k/top_10_categorical_accuracy: 0.0106 - loss: 70744.0459 - regularization_loss: 0.0000e+00 - total_loss: 70744.0459 - val_RMSE: 1.5348 - val_factorized_top_k/top_5_categorical_accuracy: 0.0135 - val_factorized_top_k/top_10_categorical_accuracy: 0.0230 - val_loss: 22811.4531 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22811.4531 - lr: 0.0086\n",
            "Epoch 4/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.3378 - factorized_top_k/top_5_categorical_accuracy: 0.0108 - factorized_top_k/top_10_categorical_accuracy: 0.0221 - loss: 70719.1758 - regularization_loss: 0.0000e+00 - total_loss: 70719.1758 - val_RMSE: 1.1412 - val_factorized_top_k/top_5_categorical_accuracy: 0.0204 - val_factorized_top_k/top_10_categorical_accuracy: 0.0366 - val_loss: 22799.9492 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22799.9492 - lr: 0.0082\n",
            "Epoch 5/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0969 - factorized_top_k/top_5_categorical_accuracy: 0.0154 - factorized_top_k/top_10_categorical_accuracy: 0.0312 - loss: 70685.8848 - regularization_loss: 0.0000e+00 - total_loss: 70685.8848 - val_RMSE: 1.0628 - val_factorized_top_k/top_5_categorical_accuracy: 0.0246 - val_factorized_top_k/top_10_categorical_accuracy: 0.0443 - val_loss: 22785.6387 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22785.6387 - lr: 0.0078\n",
            "Epoch 6/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0567 - factorized_top_k/top_5_categorical_accuracy: 0.0181 - factorized_top_k/top_10_categorical_accuracy: 0.0367 - loss: 70644.2812 - regularization_loss: 0.0000e+00 - total_loss: 70644.2812 - val_RMSE: 1.0515 - val_factorized_top_k/top_5_categorical_accuracy: 0.0263 - val_factorized_top_k/top_10_categorical_accuracy: 0.0481 - val_loss: 22768.6328 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22768.6328 - lr: 0.0074\n",
            "Epoch 7/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0498 - factorized_top_k/top_5_categorical_accuracy: 0.0196 - factorized_top_k/top_10_categorical_accuracy: 0.0396 - loss: 70596.2588 - regularization_loss: 0.0000e+00 - total_loss: 70596.2588 - val_RMSE: 1.0475 - val_factorized_top_k/top_5_categorical_accuracy: 0.0274 - val_factorized_top_k/top_10_categorical_accuracy: 0.0504 - val_loss: 22749.7617 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22749.7617 - lr: 0.0070\n",
            "Epoch 8/30\n",
            "7/7 [==============================] - 16s 2s/step - RMSE: 1.0461 - factorized_top_k/top_5_categorical_accuracy: 0.0209 - factorized_top_k/top_10_categorical_accuracy: 0.0421 - loss: 70544.2139 - regularization_loss: 0.0000e+00 - total_loss: 70544.2139 - val_RMSE: 1.0442 - val_factorized_top_k/top_5_categorical_accuracy: 0.0280 - val_factorized_top_k/top_10_categorical_accuracy: 0.0510 - val_loss: 22729.8730 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22729.8730 - lr: 0.0067\n",
            "Epoch 9/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0431 - factorized_top_k/top_5_categorical_accuracy: 0.0211 - factorized_top_k/top_10_categorical_accuracy: 0.0427 - loss: 70490.2461 - regularization_loss: 0.0000e+00 - total_loss: 70490.2461 - val_RMSE: 1.0414 - val_factorized_top_k/top_5_categorical_accuracy: 0.0280 - val_factorized_top_k/top_10_categorical_accuracy: 0.0514 - val_loss: 22709.6523 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22709.6523 - lr: 0.0064\n",
            "Epoch 10/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0403 - factorized_top_k/top_5_categorical_accuracy: 0.0217 - factorized_top_k/top_10_categorical_accuracy: 0.0436 - loss: 70435.9775 - regularization_loss: 0.0000e+00 - total_loss: 70435.9775 - val_RMSE: 1.0387 - val_factorized_top_k/top_5_categorical_accuracy: 0.0282 - val_factorized_top_k/top_10_categorical_accuracy: 0.0514 - val_loss: 22689.5996 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22689.5996 - lr: 0.0061\n",
            "Epoch 11/30\n",
            "7/7 [==============================] - 13s 2s/step - RMSE: 1.0378 - factorized_top_k/top_5_categorical_accuracy: 0.0221 - factorized_top_k/top_10_categorical_accuracy: 0.0442 - loss: 70382.5635 - regularization_loss: 0.0000e+00 - total_loss: 70382.5635 - val_RMSE: 1.0363 - val_factorized_top_k/top_5_categorical_accuracy: 0.0279 - val_factorized_top_k/top_10_categorical_accuracy: 0.0514 - val_loss: 22670.0645 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22670.0645 - lr: 0.0058\n",
            "Epoch 12/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0353 - factorized_top_k/top_5_categorical_accuracy: 0.0222 - factorized_top_k/top_10_categorical_accuracy: 0.0446 - loss: 70330.7725 - regularization_loss: 0.0000e+00 - total_loss: 70330.7725 - val_RMSE: 1.0338 - val_factorized_top_k/top_5_categorical_accuracy: 0.0276 - val_factorized_top_k/top_10_categorical_accuracy: 0.0510 - val_loss: 22651.2559 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22651.2559 - lr: 0.0055\n",
            "Epoch 13/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0329 - factorized_top_k/top_5_categorical_accuracy: 0.0222 - factorized_top_k/top_10_categorical_accuracy: 0.0449 - loss: 70281.0928 - regularization_loss: 0.0000e+00 - total_loss: 70281.0928 - val_RMSE: 1.0314 - val_factorized_top_k/top_5_categorical_accuracy: 0.0276 - val_factorized_top_k/top_10_categorical_accuracy: 0.0513 - val_loss: 22633.3145 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22633.3145 - lr: 0.0052\n",
            "Epoch 14/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0304 - factorized_top_k/top_5_categorical_accuracy: 0.0224 - factorized_top_k/top_10_categorical_accuracy: 0.0454 - loss: 70233.7979 - regularization_loss: 0.0000e+00 - total_loss: 70233.7979 - val_RMSE: 1.0290 - val_factorized_top_k/top_5_categorical_accuracy: 0.0276 - val_factorized_top_k/top_10_categorical_accuracy: 0.0514 - val_loss: 22616.3027 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22616.3027 - lr: 0.0050\n",
            "Epoch 15/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0280 - factorized_top_k/top_5_categorical_accuracy: 0.0225 - factorized_top_k/top_10_categorical_accuracy: 0.0456 - loss: 70189.0244 - regularization_loss: 0.0000e+00 - total_loss: 70189.0244 - val_RMSE: 1.0265 - val_factorized_top_k/top_5_categorical_accuracy: 0.0273 - val_factorized_top_k/top_10_categorical_accuracy: 0.0514 - val_loss: 22600.2422 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22600.2422 - lr: 0.0047\n",
            "Epoch 16/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0255 - factorized_top_k/top_5_categorical_accuracy: 0.0226 - factorized_top_k/top_10_categorical_accuracy: 0.0459 - loss: 70146.8066 - regularization_loss: 0.0000e+00 - total_loss: 70146.8066 - val_RMSE: 1.0240 - val_factorized_top_k/top_5_categorical_accuracy: 0.0273 - val_factorized_top_k/top_10_categorical_accuracy: 0.0510 - val_loss: 22585.1367 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22585.1367 - lr: 0.0045\n",
            "Epoch 17/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0231 - factorized_top_k/top_5_categorical_accuracy: 0.0228 - factorized_top_k/top_10_categorical_accuracy: 0.0461 - loss: 70107.1182 - regularization_loss: 0.0000e+00 - total_loss: 70107.1182 - val_RMSE: 1.0217 - val_factorized_top_k/top_5_categorical_accuracy: 0.0273 - val_factorized_top_k/top_10_categorical_accuracy: 0.0513 - val_loss: 22570.9570 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22570.9570 - lr: 0.0043\n",
            "Epoch 18/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0207 - factorized_top_k/top_5_categorical_accuracy: 0.0228 - factorized_top_k/top_10_categorical_accuracy: 0.0463 - loss: 70069.8779 - regularization_loss: 0.0000e+00 - total_loss: 70069.8779 - val_RMSE: 1.0194 - val_factorized_top_k/top_5_categorical_accuracy: 0.0275 - val_factorized_top_k/top_10_categorical_accuracy: 0.0510 - val_loss: 22557.6738 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22557.6738 - lr: 0.0041\n",
            "Epoch 19/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0185 - factorized_top_k/top_5_categorical_accuracy: 0.0228 - factorized_top_k/top_10_categorical_accuracy: 0.0462 - loss: 70034.9922 - regularization_loss: 0.0000e+00 - total_loss: 70034.9922 - val_RMSE: 1.0172 - val_factorized_top_k/top_5_categorical_accuracy: 0.0272 - val_factorized_top_k/top_10_categorical_accuracy: 0.0503 - val_loss: 22545.2441 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22545.2441 - lr: 0.0039\n",
            "Epoch 20/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0163 - factorized_top_k/top_5_categorical_accuracy: 0.0229 - factorized_top_k/top_10_categorical_accuracy: 0.0463 - loss: 70002.3535 - regularization_loss: 0.0000e+00 - total_loss: 70002.3535 - val_RMSE: 1.0151 - val_factorized_top_k/top_5_categorical_accuracy: 0.0273 - val_factorized_top_k/top_10_categorical_accuracy: 0.0503 - val_loss: 22533.6211 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22533.6211 - lr: 0.0037\n",
            "Epoch 21/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0143 - factorized_top_k/top_5_categorical_accuracy: 0.0230 - factorized_top_k/top_10_categorical_accuracy: 0.0464 - loss: 69971.8369 - regularization_loss: 0.0000e+00 - total_loss: 69971.8369 - val_RMSE: 1.0131 - val_factorized_top_k/top_5_categorical_accuracy: 0.0274 - val_factorized_top_k/top_10_categorical_accuracy: 0.0504 - val_loss: 22522.7598 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22522.7598 - lr: 0.0035\n",
            "Epoch 22/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0124 - factorized_top_k/top_5_categorical_accuracy: 0.0230 - factorized_top_k/top_10_categorical_accuracy: 0.0461 - loss: 69943.3105 - regularization_loss: 0.0000e+00 - total_loss: 69943.3105 - val_RMSE: 1.0113 - val_factorized_top_k/top_5_categorical_accuracy: 0.0269 - val_factorized_top_k/top_10_categorical_accuracy: 0.0503 - val_loss: 22512.6172 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22512.6172 - lr: 0.0033\n",
            "Epoch 23/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0106 - factorized_top_k/top_5_categorical_accuracy: 0.0231 - factorized_top_k/top_10_categorical_accuracy: 0.0461 - loss: 69916.6650 - regularization_loss: 0.0000e+00 - total_loss: 69916.6650 - val_RMSE: 1.0096 - val_factorized_top_k/top_5_categorical_accuracy: 0.0270 - val_factorized_top_k/top_10_categorical_accuracy: 0.0502 - val_loss: 22503.1406 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22503.1406 - lr: 0.0032\n",
            "Epoch 24/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0090 - factorized_top_k/top_5_categorical_accuracy: 0.0230 - factorized_top_k/top_10_categorical_accuracy: 0.0462 - loss: 69891.7705 - regularization_loss: 0.0000e+00 - total_loss: 69891.7705 - val_RMSE: 1.0080 - val_factorized_top_k/top_5_categorical_accuracy: 0.0273 - val_factorized_top_k/top_10_categorical_accuracy: 0.0500 - val_loss: 22494.2949 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22494.2949 - lr: 0.0030\n",
            "Epoch 25/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0075 - factorized_top_k/top_5_categorical_accuracy: 0.0231 - factorized_top_k/top_10_categorical_accuracy: 0.0463 - loss: 69868.5186 - regularization_loss: 0.0000e+00 - total_loss: 69868.5186 - val_RMSE: 1.0066 - val_factorized_top_k/top_5_categorical_accuracy: 0.0271 - val_factorized_top_k/top_10_categorical_accuracy: 0.0501 - val_loss: 22486.0312 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22486.0312 - lr: 0.0029\n",
            "Epoch 26/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0060 - factorized_top_k/top_5_categorical_accuracy: 0.0230 - factorized_top_k/top_10_categorical_accuracy: 0.0463 - loss: 69846.8027 - regularization_loss: 0.0000e+00 - total_loss: 69846.8027 - val_RMSE: 1.0052 - val_factorized_top_k/top_5_categorical_accuracy: 0.0269 - val_factorized_top_k/top_10_categorical_accuracy: 0.0500 - val_loss: 22478.3145 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22478.3145 - lr: 0.0027\n",
            "Epoch 27/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0047 - factorized_top_k/top_5_categorical_accuracy: 0.0231 - factorized_top_k/top_10_categorical_accuracy: 0.0464 - loss: 69826.5107 - regularization_loss: 0.0000e+00 - total_loss: 69826.5107 - val_RMSE: 1.0040 - val_factorized_top_k/top_5_categorical_accuracy: 0.0271 - val_factorized_top_k/top_10_categorical_accuracy: 0.0499 - val_loss: 22471.1055 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22471.1055 - lr: 0.0026\n",
            "Epoch 28/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0035 - factorized_top_k/top_5_categorical_accuracy: 0.0230 - factorized_top_k/top_10_categorical_accuracy: 0.0465 - loss: 69807.5518 - regularization_loss: 0.0000e+00 - total_loss: 69807.5518 - val_RMSE: 1.0029 - val_factorized_top_k/top_5_categorical_accuracy: 0.0269 - val_factorized_top_k/top_10_categorical_accuracy: 0.0498 - val_loss: 22464.3691 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22464.3691 - lr: 0.0025\n",
            "Epoch 29/30\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0024 - factorized_top_k/top_5_categorical_accuracy: 0.0229 - factorized_top_k/top_10_categorical_accuracy: 0.0466 - loss: 69789.8350 - regularization_loss: 0.0000e+00 - total_loss: 69789.8350 - val_RMSE: 1.0018 - val_factorized_top_k/top_5_categorical_accuracy: 0.0267 - val_factorized_top_k/top_10_categorical_accuracy: 0.0500 - val_loss: 22458.0742 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22458.0742 - lr: 0.0023\n",
            "Epoch 30/30\n",
            "7/7 [==============================] - 15s 2s/step - RMSE: 1.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0229 - factorized_top_k/top_10_categorical_accuracy: 0.0466 - loss: 69773.2764 - regularization_loss: 0.0000e+00 - total_loss: 69773.2764 - val_RMSE: 1.0008 - val_factorized_top_k/top_5_categorical_accuracy: 0.0271 - val_factorized_top_k/top_10_categorical_accuracy: 0.0500 - val_loss: 22452.1895 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22452.1895 - lr: 0.0022\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb9b4202980>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "multi_model_retrieval.fit(cached_train, epochs=30, validation_data=cached_valid, callbacks=[tf.keras.callbacks.LearningRateScheduler(scheduler)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multi_model_retrieval.fit(cached_train, epochs=40, validation_data=cached_valid, callbacks=[tf.keras.callbacks.LearningRateScheduler(scheduler)], initial_epoch=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uHmLdNpG_Pb",
        "outputId": "5235455c-69a9-457a-a5eb-ce8e43764b51"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/40\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 1.0005 - factorized_top_k/top_5_categorical_accuracy: 0.0230 - factorized_top_k/top_10_categorical_accuracy: 0.0466 - loss: 69757.7949 - regularization_loss: 0.0000e+00 - total_loss: 69757.7949 - val_RMSE: 0.9999 - val_factorized_top_k/top_5_categorical_accuracy: 0.0270 - val_factorized_top_k/top_10_categorical_accuracy: 0.0498 - val_loss: 22446.6914 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22446.6914 - lr: 0.0021\n",
            "Epoch 32/40\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9996 - factorized_top_k/top_5_categorical_accuracy: 0.0229 - factorized_top_k/top_10_categorical_accuracy: 0.0467 - loss: 69743.3105 - regularization_loss: 0.0000e+00 - total_loss: 69743.3105 - val_RMSE: 0.9991 - val_factorized_top_k/top_5_categorical_accuracy: 0.0268 - val_factorized_top_k/top_10_categorical_accuracy: 0.0497 - val_loss: 22441.5449 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22441.5449 - lr: 0.0020\n",
            "Epoch 33/40\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9988 - factorized_top_k/top_5_categorical_accuracy: 0.0229 - factorized_top_k/top_10_categorical_accuracy: 0.0467 - loss: 69729.7637 - regularization_loss: 0.0000e+00 - total_loss: 69729.7637 - val_RMSE: 0.9983 - val_factorized_top_k/top_5_categorical_accuracy: 0.0269 - val_factorized_top_k/top_10_categorical_accuracy: 0.0496 - val_loss: 22436.7305 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22436.7305 - lr: 0.0019\n",
            "Epoch 34/40\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9980 - factorized_top_k/top_5_categorical_accuracy: 0.0229 - factorized_top_k/top_10_categorical_accuracy: 0.0466 - loss: 69717.0908 - regularization_loss: 0.0000e+00 - total_loss: 69717.0908 - val_RMSE: 0.9976 - val_factorized_top_k/top_5_categorical_accuracy: 0.0268 - val_factorized_top_k/top_10_categorical_accuracy: 0.0496 - val_loss: 22432.2266 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22432.2266 - lr: 0.0018\n",
            "Epoch 35/40\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9973 - factorized_top_k/top_5_categorical_accuracy: 0.0228 - factorized_top_k/top_10_categorical_accuracy: 0.0466 - loss: 69705.2285 - regularization_loss: 0.0000e+00 - total_loss: 69705.2285 - val_RMSE: 0.9969 - val_factorized_top_k/top_5_categorical_accuracy: 0.0269 - val_factorized_top_k/top_10_categorical_accuracy: 0.0499 - val_loss: 22428.0117 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22428.0117 - lr: 0.0017\n",
            "Epoch 36/40\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9967 - factorized_top_k/top_5_categorical_accuracy: 0.0228 - factorized_top_k/top_10_categorical_accuracy: 0.0467 - loss: 69694.1221 - regularization_loss: 0.0000e+00 - total_loss: 69694.1221 - val_RMSE: 0.9963 - val_factorized_top_k/top_5_categorical_accuracy: 0.0266 - val_factorized_top_k/top_10_categorical_accuracy: 0.0497 - val_loss: 22424.0645 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22424.0645 - lr: 0.0017\n",
            "Epoch 37/40\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9961 - factorized_top_k/top_5_categorical_accuracy: 0.0228 - factorized_top_k/top_10_categorical_accuracy: 0.0467 - loss: 69683.7207 - regularization_loss: 0.0000e+00 - total_loss: 69683.7207 - val_RMSE: 0.9958 - val_factorized_top_k/top_5_categorical_accuracy: 0.0268 - val_factorized_top_k/top_10_categorical_accuracy: 0.0497 - val_loss: 22420.3691 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22420.3691 - lr: 0.0016\n",
            "Epoch 38/40\n",
            "7/7 [==============================] - 15s 2s/step - RMSE: 0.9955 - factorized_top_k/top_5_categorical_accuracy: 0.0229 - factorized_top_k/top_10_categorical_accuracy: 0.0467 - loss: 69673.9746 - regularization_loss: 0.0000e+00 - total_loss: 69673.9746 - val_RMSE: 0.9952 - val_factorized_top_k/top_5_categorical_accuracy: 0.0267 - val_factorized_top_k/top_10_categorical_accuracy: 0.0498 - val_loss: 22416.9023 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22416.9023 - lr: 0.0015\n",
            "Epoch 39/40\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9950 - factorized_top_k/top_5_categorical_accuracy: 0.0229 - factorized_top_k/top_10_categorical_accuracy: 0.0468 - loss: 69664.8457 - regularization_loss: 0.0000e+00 - total_loss: 69664.8457 - val_RMSE: 0.9947 - val_factorized_top_k/top_5_categorical_accuracy: 0.0267 - val_factorized_top_k/top_10_categorical_accuracy: 0.0500 - val_loss: 22413.6562 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22413.6562 - lr: 0.0014\n",
            "Epoch 40/40\n",
            "7/7 [==============================] - 12s 2s/step - RMSE: 0.9945 - factorized_top_k/top_5_categorical_accuracy: 0.0231 - factorized_top_k/top_10_categorical_accuracy: 0.0467 - loss: 69656.2891 - regularization_loss: 0.0000e+00 - total_loss: 69656.2891 - val_RMSE: 0.9943 - val_factorized_top_k/top_5_categorical_accuracy: 0.0267 - val_factorized_top_k/top_10_categorical_accuracy: 0.0498 - val_loss: 22410.6152 - val_regularization_loss: 0.0000e+00 - val_total_loss: 22410.6152 - lr: 0.0014\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb9b9dbc940>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Model & Evaluation"
      ],
      "metadata": {
        "id": "i3hBkBhwWYV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll choose the first model since it has the best performance with fewer parameters"
      ],
      "metadata": {
        "id": "J9htjBsGWcXy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before testing it on the test set, we'll retrain it on the train + valdation sets combined."
      ],
      "metadata": {
        "id": "mpWpRF0h2BUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retraining on train + valid"
      ],
      "metadata": {
        "id": "BSShoW5p3BoI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57c4d01d-8008-4e0c-fd7c-0977bb178932",
        "id": "oulY7v1sIM5C"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec={'userId': TensorSpec(shape=(), dtype=tf.string, name=None), 'movieTitle': TensorSpec(shape=(), dtype=tf.string, name=None), 'rating': TensorSpec(shape=(), dtype=tf.float64, name=None)}>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "total_rating_dataset = tf.data.Dataset.from_tensor_slices({'userId':ratings['userId'].values, 'movieTitle': ratings['movieTitle'].values, 'rating': ratings['rating'].values})\n",
        "total_rating_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ZVlezl4OIM5E"
      },
      "outputs": [],
      "source": [
        "total_movie_dataset = tf.data.Dataset.from_tensor_slices(ratings['movieTitle'].unique())\n",
        "total_user_dataset = tf.data.Dataset.from_tensor_slices(ratings['userId'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Mp4x-UHJIM5F"
      },
      "outputs": [],
      "source": [
        "user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None, name='users_lookup', num_oov_indices=0)\n",
        "movie_titles_vocabulary = tf.keras.layers.StringLookup(mask_token=None, name='movies_lookup', num_oov_indices=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "657A0HYUIM5H"
      },
      "outputs": [],
      "source": [
        "user_ids_vocabulary.adapt(total_user_dataset.map(lambda x: x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "KkPCV-JJIM5H"
      },
      "outputs": [],
      "source": [
        "movie_titles_vocabulary.adapt(total_movie_dataset.map(lambda x: x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa225f15-dcdd-4641-a7e3-b7325a871719",
        "id": "LVif3BicIM5I"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(610, 5389)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "n_users = user_ids_vocabulary.vocabulary_size()\n",
        "n_movies = movie_titles_vocabulary.vocabulary_size()\n",
        "n_users, n_movies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultitaskRecommender(tfrs.Model):\n",
        "  def __init__(self, embedding_dimension=32, rating_weight: float=1., retrieval_weight: float =1.) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    # Set up user and movie representations.\n",
        "    self.movie_model = tf.keras.Sequential(\n",
        "        [\n",
        "          movie_titles_vocabulary,\n",
        "          tf.keras.layers.Embedding(n_movies, embedding_dimension, name='movie_embedding')\n",
        "        ],\n",
        "        name='movie_model')\n",
        "\n",
        "    self.user_model = tf.keras.Sequential(\n",
        "        [\n",
        "          user_ids_vocabulary,\n",
        "          tf.keras.layers.Embedding(n_users, embedding_dimension, name='user_embedding')\n",
        "        ],\n",
        "        name='user_model')\n",
        "\n",
        "    # Set up MLP to predict rating from user and movie representation\n",
        "    self.rating_model = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.Dense(256, activation='relu'),\n",
        "            tf.keras.layers.Dense(128,  activation='relu'),\n",
        "            tf.keras.layers.Dense(1)\n",
        "        ],\n",
        "        name='rating_model')\n",
        "\n",
        "    # Set up ranking and retrieval tasks\n",
        "    self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
        "          loss=tf.keras.losses.MeanSquaredError(name='MSE'),\n",
        "          metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
        "      )\n",
        "\n",
        "    self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
        "        metrics=tfrs.metrics.FactorizedTopK(\n",
        "            candidates=movie_dataset.batch(128).map(self.movie_model),\n",
        "            ks = (5,10)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Set up weights for rating task and retrieval task\n",
        "    self.rating_weight = rating_weight\n",
        "    self.retrieval_weight = retrieval_weight\n",
        "\n",
        "  def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
        "    # We pick out the user features and pass them into the user model.\n",
        "    user_embeddings = self.user_model(features[\"userId\"])\n",
        "    # And pick out the movie features and pass them into the movie model.\n",
        "    movie_embeddings = self.movie_model(features[\"movieTitle\"])\n",
        "\n",
        "    return (\n",
        "        user_embeddings,\n",
        "        movie_embeddings,\n",
        "        # We apply the multi-layered rating model to a concatentation of\n",
        "        # user and movie embeddings.\n",
        "        self.rating_model(\n",
        "            tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
        "        ),\n",
        "    )\n",
        "\n",
        "  def compute_loss(self, features_label: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "\n",
        "    ratings = features_label.pop(\"rating\")\n",
        "\n",
        "    user_embeddings, movie_embeddings, rating_predictions = self(features_label)\n",
        "\n",
        "    # We compute the loss for each task.\n",
        "    rating_loss = self.rating_task(labels=ratings, predictions=rating_predictions)\n",
        "    retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
        "\n",
        "    # And combine them using the loss weights.\n",
        "    return self.rating_weight*rating_loss + self.retrieval_weight*retrieval_loss"
      ],
      "metadata": {
        "id": "ICsF_U2JIpvW"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_model_final = MultitaskRecommender(embedding_dimension=32, rating_weight=1., retrieval_weight=1)\n",
        "multi_model_final.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.01))"
      ],
      "metadata": {
        "id": "a0dfUcDTJLoy"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cached_total = total_rating_dataset.shuffle(100_000).batch(8192).cache()"
      ],
      "metadata": {
        "id": "L_Be78NsJRBD"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P9fRu1sbY-Y",
        "outputId": "1c0357ae-1731-49fb-c91b-451adfd2eab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "10/10 [==============================] - 12s 1s/step - RMSE: 3.2467 - factorized_top_k/top_5_categorical_accuracy: 8.8531e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0018 - loss: 66796.1555 - regularization_loss: 0.0000e+00 - total_loss: 66796.1555 - lr: 0.0095\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 9s 864ms/step - RMSE: 1.9515 - factorized_top_k/top_5_categorical_accuracy: 0.0026 - factorized_top_k/top_10_categorical_accuracy: 0.0054 - loss: 66775.9709 - regularization_loss: 0.0000e+00 - total_loss: 66775.9709 - lr: 0.0090\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 8s 752ms/step - RMSE: 1.1149 - factorized_top_k/top_5_categorical_accuracy: 0.0081 - factorized_top_k/top_10_categorical_accuracy: 0.0173 - loss: 66745.0511 - regularization_loss: 0.0000e+00 - total_loss: 66745.0511 - lr: 0.0086\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 8s 728ms/step - RMSE: 1.0411 - factorized_top_k/top_5_categorical_accuracy: 0.0122 - factorized_top_k/top_10_categorical_accuracy: 0.0260 - loss: 66694.1357 - regularization_loss: 0.0000e+00 - total_loss: 66694.1357 - lr: 0.0082\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 8s 849ms/step - RMSE: 1.0268 - factorized_top_k/top_5_categorical_accuracy: 0.0136 - factorized_top_k/top_10_categorical_accuracy: 0.0300 - loss: 66624.2209 - regularization_loss: 0.0000e+00 - total_loss: 66624.2209 - lr: 0.0078\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 7s 737ms/step - RMSE: 1.0169 - factorized_top_k/top_5_categorical_accuracy: 0.0148 - factorized_top_k/top_10_categorical_accuracy: 0.0320 - loss: 66542.9588 - regularization_loss: 0.0000e+00 - total_loss: 66542.9588 - lr: 0.0074\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 8s 808ms/step - RMSE: 1.0114 - factorized_top_k/top_5_categorical_accuracy: 0.0152 - factorized_top_k/top_10_categorical_accuracy: 0.0333 - loss: 66457.4581 - regularization_loss: 0.0000e+00 - total_loss: 66457.4581 - lr: 0.0070\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 8s 858ms/step - RMSE: 1.0076 - factorized_top_k/top_5_categorical_accuracy: 0.0157 - factorized_top_k/top_10_categorical_accuracy: 0.0339 - loss: 66372.4744 - regularization_loss: 0.0000e+00 - total_loss: 66372.4744 - lr: 0.0067\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 7s 732ms/step - RMSE: 1.0039 - factorized_top_k/top_5_categorical_accuracy: 0.0162 - factorized_top_k/top_10_categorical_accuracy: 0.0344 - loss: 66290.7472 - regularization_loss: 0.0000e+00 - total_loss: 66290.7472 - lr: 0.0064\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 8s 848ms/step - RMSE: 1.0002 - factorized_top_k/top_5_categorical_accuracy: 0.0166 - factorized_top_k/top_10_categorical_accuracy: 0.0348 - loss: 66213.6428 - regularization_loss: 0.0000e+00 - total_loss: 66213.6428 - lr: 0.0061\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 8s 840ms/step - RMSE: 0.9967 - factorized_top_k/top_5_categorical_accuracy: 0.0166 - factorized_top_k/top_10_categorical_accuracy: 0.0354 - loss: 66141.7053 - regularization_loss: 0.0000e+00 - total_loss: 66141.7053 - lr: 0.0058\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 7s 732ms/step - RMSE: 0.9934 - factorized_top_k/top_5_categorical_accuracy: 0.0168 - factorized_top_k/top_10_categorical_accuracy: 0.0357 - loss: 66075.0263 - regularization_loss: 0.0000e+00 - total_loss: 66075.0263 - lr: 0.0055\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 8s 813ms/step - RMSE: 0.9905 - factorized_top_k/top_5_categorical_accuracy: 0.0170 - factorized_top_k/top_10_categorical_accuracy: 0.0360 - loss: 66013.4496 - regularization_loss: 0.0000e+00 - total_loss: 66013.4496 - lr: 0.0052\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 8s 859ms/step - RMSE: 0.9880 - factorized_top_k/top_5_categorical_accuracy: 0.0171 - factorized_top_k/top_10_categorical_accuracy: 0.0362 - loss: 65956.6918 - regularization_loss: 0.0000e+00 - total_loss: 65956.6918 - lr: 0.0050\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 7s 722ms/step - RMSE: 0.9857 - factorized_top_k/top_5_categorical_accuracy: 0.0172 - factorized_top_k/top_10_categorical_accuracy: 0.0361 - loss: 65904.4141 - regularization_loss: 0.0000e+00 - total_loss: 65904.4141 - lr: 0.0047\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 8s 833ms/step - RMSE: 0.9837 - factorized_top_k/top_5_categorical_accuracy: 0.0171 - factorized_top_k/top_10_categorical_accuracy: 0.0363 - loss: 65856.2798 - regularization_loss: 0.0000e+00 - total_loss: 65856.2798 - lr: 0.0045\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 8s 794ms/step - RMSE: 0.9819 - factorized_top_k/top_5_categorical_accuracy: 0.0172 - factorized_top_k/top_10_categorical_accuracy: 0.0364 - loss: 65811.9354 - regularization_loss: 0.0000e+00 - total_loss: 65811.9354 - lr: 0.0043\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 7s 720ms/step - RMSE: 0.9804 - factorized_top_k/top_5_categorical_accuracy: 0.0172 - factorized_top_k/top_10_categorical_accuracy: 0.0365 - loss: 65771.0710 - regularization_loss: 0.0000e+00 - total_loss: 65771.0710 - lr: 0.0041\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 7s 717ms/step - RMSE: 0.9790 - factorized_top_k/top_5_categorical_accuracy: 0.0173 - factorized_top_k/top_10_categorical_accuracy: 0.0365 - loss: 65733.3864 - regularization_loss: 0.0000e+00 - total_loss: 65733.3864 - lr: 0.0039\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 8s 848ms/step - RMSE: 0.9777 - factorized_top_k/top_5_categorical_accuracy: 0.0174 - factorized_top_k/top_10_categorical_accuracy: 0.0366 - loss: 65698.6009 - regularization_loss: 0.0000e+00 - total_loss: 65698.6009 - lr: 0.0037\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 8s 785ms/step - RMSE: 0.9766 - factorized_top_k/top_5_categorical_accuracy: 0.0175 - factorized_top_k/top_10_categorical_accuracy: 0.0365 - loss: 65666.4702 - regularization_loss: 0.0000e+00 - total_loss: 65666.4702 - lr: 0.0035\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 7s 726ms/step - RMSE: 0.9756 - factorized_top_k/top_5_categorical_accuracy: 0.0176 - factorized_top_k/top_10_categorical_accuracy: 0.0367 - loss: 65636.7635 - regularization_loss: 0.0000e+00 - total_loss: 65636.7635 - lr: 0.0033\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 8s 842ms/step - RMSE: 0.9747 - factorized_top_k/top_5_categorical_accuracy: 0.0177 - factorized_top_k/top_10_categorical_accuracy: 0.0368 - loss: 65609.2685 - regularization_loss: 0.0000e+00 - total_loss: 65609.2685 - lr: 0.0032\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 8s 851ms/step - RMSE: 0.9738 - factorized_top_k/top_5_categorical_accuracy: 0.0178 - factorized_top_k/top_10_categorical_accuracy: 0.0367 - loss: 65583.8054 - regularization_loss: 0.0000e+00 - total_loss: 65583.8054 - lr: 0.0030\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 7s 723ms/step - RMSE: 0.9731 - factorized_top_k/top_5_categorical_accuracy: 0.0178 - factorized_top_k/top_10_categorical_accuracy: 0.0366 - loss: 65560.2053 - regularization_loss: 0.0000e+00 - total_loss: 65560.2053 - lr: 0.0029\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 8s 827ms/step - RMSE: 0.9724 - factorized_top_k/top_5_categorical_accuracy: 0.0178 - factorized_top_k/top_10_categorical_accuracy: 0.0367 - loss: 65538.3075 - regularization_loss: 0.0000e+00 - total_loss: 65538.3075 - lr: 0.0027\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 8s 847ms/step - RMSE: 0.9717 - factorized_top_k/top_5_categorical_accuracy: 0.0178 - factorized_top_k/top_10_categorical_accuracy: 0.0366 - loss: 65517.9773 - regularization_loss: 0.0000e+00 - total_loss: 65517.9773 - lr: 0.0026\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 7s 734ms/step - RMSE: 0.9712 - factorized_top_k/top_5_categorical_accuracy: 0.0179 - factorized_top_k/top_10_categorical_accuracy: 0.0368 - loss: 65499.0895 - regularization_loss: 0.0000e+00 - total_loss: 65499.0895 - lr: 0.0025\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 7s 726ms/step - RMSE: 0.9706 - factorized_top_k/top_5_categorical_accuracy: 0.0180 - factorized_top_k/top_10_categorical_accuracy: 0.0368 - loss: 65481.5234 - regularization_loss: 0.0000e+00 - total_loss: 65481.5234 - lr: 0.0023\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 8s 838ms/step - RMSE: 0.9701 - factorized_top_k/top_5_categorical_accuracy: 0.0180 - factorized_top_k/top_10_categorical_accuracy: 0.0368 - loss: 65465.1797 - regularization_loss: 0.0000e+00 - total_loss: 65465.1797 - lr: 0.0022\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb9af6d4ee0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "multi_model_final.fit(cached_total, epochs=30, callbacks = [tf.keras.callbacks.LearningRateScheduler(scheduler)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "Rr7AdTL42RtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cached_test = test_rating_dataset.batch(4096).cache()"
      ],
      "metadata": {
        "id": "8SxUMOv33I_N"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_model_final.evaluate(cached_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DowkJg4o20JA",
        "outputId": "c6c87eb1-3cf7-423a-8afa-b561e965f4cc"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 2s 418ms/step - RMSE: 0.9608 - factorized_top_k/top_5_categorical_accuracy: 0.0222 - factorized_top_k/top_10_categorical_accuracy: 0.0410 - loss: 29262.4836 - regularization_loss: 0.0000e+00 - total_loss: 29262.4836\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9608275294303894,\n",
              " 0.022232424467802048,\n",
              " 0.0409889817237854,\n",
              " 23123.341796875,\n",
              " 0,\n",
              " 23123.341796875]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3dGH_I7A_ZO"
      },
      "source": [
        "## Indexers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTzjq0qLBCEX"
      },
      "source": [
        "Indexers store the embedding of the possible candidates as keys. When it receives a query, it embeds the query and retrieves the closest keys.\n",
        "\n",
        "For our recommendation task, it stores the embeddings of movies and the embedding of users. When we want to recommend for a user, it gets the movies whose embedding are the most similar (using dot product) to the user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "neJAJVwbReNd"
      },
      "outputs": [],
      "source": [
        "# Use brute-force search to set up retrieval using the trained representations.\n",
        "user_recommender = tfrs.layers.factorized_top_k.BruteForce(multi_model_final.user_model, k=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "_GXqrR69UeWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4913595f-3db5-41b6-d4f6-17bcbcaac23d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x7fb9af7f7dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "user_recommender.index_from_dataset(\n",
        "    total_movie_dataset.batch(100).map(lambda title: (title, multi_model_final.movie_model(title))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "gHnxsVx1UfmF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6d8f35b-197c-46c3-aee3-efa9170c31a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 recommendations for user 42: [[b'Foxfire (1996)' b'Cutthroat Island (1995)'\n",
            "  b'Postman, The (Postino, Il) (1994)' b'Boxing Helena (1993)'\n",
            "  b'All About Eve (1950)' b'When Night Is Falling (1995)'\n",
            "  b'Free Willy 2: The Adventure Home (1995)' b'Tom and Huck (1995)'\n",
            "  b\"Jason's Lyric (1994)\" b'Little Rascals, The (1994)']]\n"
          ]
        }
      ],
      "source": [
        "# Get some recommendations.\n",
        "_, titles = user_recommender(tf.constant([\"90\"]))\n",
        "print(f\"Top 3 recommendations for user 42: {titles[:,:10]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPI7iMrtBfvk"
      },
      "source": [
        "#### Item-Item recommendation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugcrEkD8BjJu"
      },
      "source": [
        "For items similarity, we can use the embedding of movies as both query and keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "mb_nnuziM73X"
      },
      "outputs": [],
      "source": [
        "movie_recommender = tfrs.layers.factorized_top_k.BruteForce(multi_model_final.movie_model, k=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "kbX-Uob8NH9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e87b481-0ac6-45ca-eae9-09f1956cf9f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x7fb9a2e5dd20>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "movie_recommender.index_from_dataset(\n",
        "    total_movie_dataset.batch(100).map(lambda title: (title, multi_model_final.movie_model(title))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Fy8ijm54PYuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da24a478-2157-4942-fd98-0d4dd3a2fbfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 recommendations for movie 42: [[b'Withnail & I (1987)' b'Mother (1996)' b'Escape from New York (1981)'\n",
            "  b'Indian Summer (a.k.a. Alive & Kicking) (1996)'\n",
            "  b'Kiss Me, Guido (1997)' b'Event Horizon (1997)'\n",
            "  b'Wings of Desire (Himmel \\xc3\\xbcber Berlin, Der) (1987)'\n",
            "  b'Wishmaster (1997)' b'Kull the Conqueror (1997)' b'Stripes (1981)']]\n"
          ]
        }
      ],
      "source": [
        "# Get some recommendations.\n",
        "_, titles2 = movie_recommender(tf.constant([\"Withnail & I (1987)\"]))\n",
        "print(f\"Top 3 recommendations for movie 42: {titles2[:,:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Ym-Ppz3OthFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e02e96be-e2e0-405a-d392-7e2a58c6232f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 recommendations for movie 42: [[b'Christmas Story, A (1983)' b'Foxfire (1996)' b'Murder at 1600 (1997)'\n",
            "  b\"When the Cat's Away (Chacun cherche son chat) (1996)\" b'Shaft (2000)'\n",
            "  b'Mexican, The (2001)'\n",
            "  b\"Cat o' Nine Tails, The (Gatto a nove code, Il) (1971)\"\n",
            "  b'Breakfast Club, The (1985)' b'Wildcats (1986)'\n",
            "  b'Bronx Tale, A (1993)']]\n"
          ]
        }
      ],
      "source": [
        "# Get some recommendations.\n",
        "_, titles2 = movie_recommender(tf.constant([\"Freaky Friday (2003)\"]), k=25)\n",
        "print(f\"Top 3 recommendations for movie 42: {titles2[:,:10]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exporting the model"
      ],
      "metadata": {
        "id": "0Cde_qVN3P1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll save and export this model to use in our movie recommendation platform.\n",
        "\n",
        "This time we'll retrain it on the entire movielens 100k dataset."
      ],
      "metadata": {
        "id": "JrD4jaYj3SM1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "BHF9T4R23mYy"
      },
      "outputs": [],
      "source": [
        "movielens_dataset = tf.data.Dataset.from_tensor_slices({'userId':ratings['userId'].values, 'movieTitle': ratings['movieTitle'].values, 'rating': ratings['rating'].values})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "v4vB9auD3mY5"
      },
      "outputs": [],
      "source": [
        "movie_dataset = tf.data.Dataset.from_tensor_slices(ratings['movieTitle'].unique())\n",
        "user_dataset = tf.data.Dataset.from_tensor_slices(ratings['userId'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "YJcnOQdO3mY5"
      },
      "outputs": [],
      "source": [
        "user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None, name='users_lookup', num_oov_indices=0)\n",
        "movie_titles_vocabulary = tf.keras.layers.StringLookup(mask_token=None, name='movies_lookup', num_oov_indices=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "0NQ18s8W3mY6"
      },
      "outputs": [],
      "source": [
        "user_ids_vocabulary.adapt(user_dataset.map(lambda x: x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "xEn26GIb3mY6"
      },
      "outputs": [],
      "source": [
        "movie_titles_vocabulary.adapt(movie_dataset.map(lambda x: x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e36fbb6-6172-4078-d6cc-7ff4bc436eb9",
        "id": "Y834_AS33mY6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(610, 5389)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "n_users = user_ids_vocabulary.vocabulary_size()\n",
        "n_movies = movie_titles_vocabulary.vocabulary_size()\n",
        "n_users, n_movies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultitaskRecommender(tfrs.Model):\n",
        "  def __init__(self, embedding_dimension=32, rating_weight: float=1., retrieval_weight: float =1.) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    # Set up user and movie representations.\n",
        "    self.movie_model = tf.keras.Sequential(\n",
        "        [\n",
        "          movie_titles_vocabulary,\n",
        "          tf.keras.layers.Embedding(n_movies, embedding_dimension, name='movie_embedding')\n",
        "        ],\n",
        "        name='movie_model')\n",
        "\n",
        "    self.user_model = tf.keras.Sequential(\n",
        "        [\n",
        "          user_ids_vocabulary,\n",
        "          tf.keras.layers.Embedding(n_users, embedding_dimension, name='user_embedding')\n",
        "        ],\n",
        "        name='user_model')\n",
        "\n",
        "    # Set up MLP to predict rating from user and movie representation\n",
        "    self.rating_model = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.Dense(256, activation='relu'),\n",
        "            tf.keras.layers.Dense(128,  activation='relu'),\n",
        "            tf.keras.layers.Dense(1)\n",
        "        ],\n",
        "        name='rating_model')\n",
        "\n",
        "    # Set up ranking and retrieval tasks\n",
        "    self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
        "          loss=tf.keras.losses.MeanSquaredError(name='MSE'),\n",
        "          metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"RMSE\")],\n",
        "      )\n",
        "\n",
        "    self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
        "        metrics=tfrs.metrics.FactorizedTopK(\n",
        "            candidates=movie_dataset.batch(128).map(self.movie_model),\n",
        "            ks = (5,10)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Set up weights for rating task and retrieval task\n",
        "    self.rating_weight = rating_weight\n",
        "    self.retrieval_weight = retrieval_weight\n",
        "\n",
        "  def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
        "    # We pick out the user features and pass them into the user model.\n",
        "    user_embeddings = self.user_model(features[\"userId\"])\n",
        "    # And pick out the movie features and pass them into the movie model.\n",
        "    movie_embeddings = self.movie_model(features[\"movieTitle\"])\n",
        "\n",
        "    return (\n",
        "        user_embeddings,\n",
        "        movie_embeddings,\n",
        "        # We apply the multi-layered rating model to a concatentation of\n",
        "        # user and movie embeddings.\n",
        "        self.rating_model(\n",
        "            tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
        "        ),\n",
        "    )\n",
        "\n",
        "  def compute_loss(self, features_label: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "\n",
        "    ratings = features_label.pop(\"rating\")\n",
        "\n",
        "    user_embeddings, movie_embeddings, rating_predictions = self(features_label)\n",
        "\n",
        "    # We compute the loss for each task.\n",
        "    rating_loss = self.rating_task(labels=ratings, predictions=rating_predictions)\n",
        "    retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
        "\n",
        "    # And combine them using the loss weights.\n",
        "    return self.rating_weight*rating_loss + self.retrieval_weight*retrieval_loss"
      ],
      "metadata": {
        "id": "RCCbPqRv3RfG"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = MultitaskRecommender(embedding_dimension=32, rating_weight=1., retrieval_weight=1)\n",
        "final_model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.01))"
      ],
      "metadata": {
        "id": "mXtb9RqB37AE"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cached_movielens = movielens_dataset.shuffle(100_000).batch(8192).cache()"
      ],
      "metadata": {
        "id": "Us0kvMdi37AL"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48dc8377-e465-4803-85ba-e997cce84b2e",
        "id": "2cwRPRHw37AL"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "10/10 [==============================] - 15s 1s/step - RMSE: 3.2921 - factorized_top_k/top_5_categorical_accuracy: 8.0832e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0017 - loss: 66796.7663 - regularization_loss: 0.0000e+00 - total_loss: 66796.7663 - lr: 0.0095\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 11s 1s/step - RMSE: 2.0996 - factorized_top_k/top_5_categorical_accuracy: 0.0023 - factorized_top_k/top_10_categorical_accuracy: 0.0048 - loss: 66778.9851 - regularization_loss: 0.0000e+00 - total_loss: 66778.9851 - lr: 0.0090\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 11s 1s/step - RMSE: 1.1737 - factorized_top_k/top_5_categorical_accuracy: 0.0071 - factorized_top_k/top_10_categorical_accuracy: 0.0153 - loss: 66754.2443 - regularization_loss: 0.0000e+00 - total_loss: 66754.2443 - lr: 0.0086\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 10s 1s/step - RMSE: 1.0604 - factorized_top_k/top_5_categorical_accuracy: 0.0114 - factorized_top_k/top_10_categorical_accuracy: 0.0251 - loss: 66713.6491 - regularization_loss: 0.0000e+00 - total_loss: 66713.6491 - lr: 0.0082\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 8s 808ms/step - RMSE: 1.0476 - factorized_top_k/top_5_categorical_accuracy: 0.0137 - factorized_top_k/top_10_categorical_accuracy: 0.0299 - loss: 66654.1193 - regularization_loss: 0.0000e+00 - total_loss: 66654.1193 - lr: 0.0078\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 11s 1s/step - RMSE: 1.0322 - factorized_top_k/top_5_categorical_accuracy: 0.0147 - factorized_top_k/top_10_categorical_accuracy: 0.0331 - loss: 66580.2791 - regularization_loss: 0.0000e+00 - total_loss: 66580.2791 - lr: 0.0074\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 12s 1s/step - RMSE: 1.0177 - factorized_top_k/top_5_categorical_accuracy: 0.0155 - factorized_top_k/top_10_categorical_accuracy: 0.0343 - loss: 66498.4041 - regularization_loss: 0.0000e+00 - total_loss: 66498.4041 - lr: 0.0070\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 9s 918ms/step - RMSE: 1.0071 - factorized_top_k/top_5_categorical_accuracy: 0.0161 - factorized_top_k/top_10_categorical_accuracy: 0.0352 - loss: 66413.6712 - regularization_loss: 0.0000e+00 - total_loss: 66413.6712 - lr: 0.0067\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 8s 804ms/step - RMSE: 0.9997 - factorized_top_k/top_5_categorical_accuracy: 0.0165 - factorized_top_k/top_10_categorical_accuracy: 0.0361 - loss: 66329.6186 - regularization_loss: 0.0000e+00 - total_loss: 66329.6186 - lr: 0.0064\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 9s 895ms/step - RMSE: 0.9943 - factorized_top_k/top_5_categorical_accuracy: 0.0168 - factorized_top_k/top_10_categorical_accuracy: 0.0365 - loss: 66248.4084 - regularization_loss: 0.0000e+00 - total_loss: 66248.4084 - lr: 0.0061\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 9s 928ms/step - RMSE: 0.9899 - factorized_top_k/top_5_categorical_accuracy: 0.0169 - factorized_top_k/top_10_categorical_accuracy: 0.0369 - loss: 66171.2266 - regularization_loss: 0.0000e+00 - total_loss: 66171.2266 - lr: 0.0058\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 9s 852ms/step - RMSE: 0.9863 - factorized_top_k/top_5_categorical_accuracy: 0.0170 - factorized_top_k/top_10_categorical_accuracy: 0.0370 - loss: 66098.6612 - regularization_loss: 0.0000e+00 - total_loss: 66098.6612 - lr: 0.0055\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 8s 789ms/step - RMSE: 0.9832 - factorized_top_k/top_5_categorical_accuracy: 0.0172 - factorized_top_k/top_10_categorical_accuracy: 0.0370 - loss: 66030.8949 - regularization_loss: 0.0000e+00 - total_loss: 66030.8949 - lr: 0.0052\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 8s 817ms/step - RMSE: 0.9806 - factorized_top_k/top_5_categorical_accuracy: 0.0172 - factorized_top_k/top_10_categorical_accuracy: 0.0372 - loss: 65967.8885 - regularization_loss: 0.0000e+00 - total_loss: 65967.8885 - lr: 0.0050\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 9s 909ms/step - RMSE: 0.9783 - factorized_top_k/top_5_categorical_accuracy: 0.0172 - factorized_top_k/top_10_categorical_accuracy: 0.0372 - loss: 65909.4723 - regularization_loss: 0.0000e+00 - total_loss: 65909.4723 - lr: 0.0047\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 9s 904ms/step - RMSE: 0.9763 - factorized_top_k/top_5_categorical_accuracy: 0.0173 - factorized_top_k/top_10_categorical_accuracy: 0.0373 - loss: 65855.4055 - regularization_loss: 0.0000e+00 - total_loss: 65855.4055 - lr: 0.0045\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 8s 800ms/step - RMSE: 0.9744 - factorized_top_k/top_5_categorical_accuracy: 0.0173 - factorized_top_k/top_10_categorical_accuracy: 0.0375 - loss: 65805.4041 - regularization_loss: 0.0000e+00 - total_loss: 65805.4041 - lr: 0.0043\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 9s 891ms/step - RMSE: 0.9728 - factorized_top_k/top_5_categorical_accuracy: 0.0174 - factorized_top_k/top_10_categorical_accuracy: 0.0377 - loss: 65759.1839 - regularization_loss: 0.0000e+00 - total_loss: 65759.1839 - lr: 0.0041\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 10s 989ms/step - RMSE: 0.9713 - factorized_top_k/top_5_categorical_accuracy: 0.0175 - factorized_top_k/top_10_categorical_accuracy: 0.0379 - loss: 65716.4624 - regularization_loss: 0.0000e+00 - total_loss: 65716.4624 - lr: 0.0039\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 9s 856ms/step - RMSE: 0.9700 - factorized_top_k/top_5_categorical_accuracy: 0.0175 - factorized_top_k/top_10_categorical_accuracy: 0.0378 - loss: 65676.9645 - regularization_loss: 0.0000e+00 - total_loss: 65676.9645 - lr: 0.0037\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 8s 799ms/step - RMSE: 0.9688 - factorized_top_k/top_5_categorical_accuracy: 0.0175 - factorized_top_k/top_10_categorical_accuracy: 0.0379 - loss: 65640.4339 - regularization_loss: 0.0000e+00 - total_loss: 65640.4339 - lr: 0.0035\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 9s 910ms/step - RMSE: 0.9677 - factorized_top_k/top_5_categorical_accuracy: 0.0177 - factorized_top_k/top_10_categorical_accuracy: 0.0379 - loss: 65606.6300 - regularization_loss: 0.0000e+00 - total_loss: 65606.6300 - lr: 0.0033\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 9s 911ms/step - RMSE: 0.9668 - factorized_top_k/top_5_categorical_accuracy: 0.0177 - factorized_top_k/top_10_categorical_accuracy: 0.0380 - loss: 65575.3331 - regularization_loss: 0.0000e+00 - total_loss: 65575.3331 - lr: 0.0032\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 9s 871ms/step - RMSE: 0.9659 - factorized_top_k/top_5_categorical_accuracy: 0.0176 - factorized_top_k/top_10_categorical_accuracy: 0.0379 - loss: 65546.3388 - regularization_loss: 0.0000e+00 - total_loss: 65546.3388 - lr: 0.0030\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 8s 787ms/step - RMSE: 0.9651 - factorized_top_k/top_5_categorical_accuracy: 0.0176 - factorized_top_k/top_10_categorical_accuracy: 0.0377 - loss: 65519.4560 - regularization_loss: 0.0000e+00 - total_loss: 65519.4560 - lr: 0.0029\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 9s 885ms/step - RMSE: 0.9644 - factorized_top_k/top_5_categorical_accuracy: 0.0177 - factorized_top_k/top_10_categorical_accuracy: 0.0378 - loss: 65494.5192 - regularization_loss: 0.0000e+00 - total_loss: 65494.5192 - lr: 0.0027\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 9s 927ms/step - RMSE: 0.9637 - factorized_top_k/top_5_categorical_accuracy: 0.0177 - factorized_top_k/top_10_categorical_accuracy: 0.0378 - loss: 65471.3679 - regularization_loss: 0.0000e+00 - total_loss: 65471.3679 - lr: 0.0026\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 8s 831ms/step - RMSE: 0.9631 - factorized_top_k/top_5_categorical_accuracy: 0.0178 - factorized_top_k/top_10_categorical_accuracy: 0.0379 - loss: 65449.8608 - regularization_loss: 0.0000e+00 - total_loss: 65449.8608 - lr: 0.0025\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 9s 844ms/step - RMSE: 0.9626 - factorized_top_k/top_5_categorical_accuracy: 0.0177 - factorized_top_k/top_10_categorical_accuracy: 0.0379 - loss: 65429.8707 - regularization_loss: 0.0000e+00 - total_loss: 65429.8707 - lr: 0.0023\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 9s 911ms/step - RMSE: 0.9621 - factorized_top_k/top_5_categorical_accuracy: 0.0178 - factorized_top_k/top_10_categorical_accuracy: 0.0379 - loss: 65411.2777 - regularization_loss: 0.0000e+00 - total_loss: 65411.2777 - lr: 0.0022\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb9a2da50f0>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "final_model.fit(cached_movielens, epochs=30, callbacks = [tf.keras.callbacks.LearningRateScheduler(scheduler)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.retrieval_task =  tfrs.tasks.Retrieval()"
      ],
      "metadata": {
        "id": "VaOCTzPBVTb5"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.save('multitask_recommender')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cTRB523VMiZ",
        "outputId": "c3af73b3-9ad4-4e12-aea4-44ba3ec9882d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow_recommenders.tasks.retrieval.Retrieval object at 0x7fb99e26e7a0>, because it is not built.\n",
            "WARNING:absl:Function `_wrapped_model` contains input name(s) movieTitle, userId with unsupported characters which will be renamed to movietitle, userid in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as ranking_4_layer_call_fn, ranking_4_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded = tf.keras.models.load_model('multitask_recommender')"
      ],
      "metadata": {
        "id": "EgXxNHDjVMrb"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings['movieTitle'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqTdwY8UXVhn",
        "outputId": "47612517-e45c-43fc-f64e-1c932268df8a"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Jumanji (1995)', 'Waiting to Exhale (1995)', 'Sabrina (1995)',\n",
              "       ..., 'Source Code (2011)', 'Master, The (2012)', 'Breathe (2014)'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = {\"userId\": tf.tile([str(52)], [5389]), \"movieTitle\": ratings['movieTitle'].unique()}\n",
        "user_embeddings, movie_embeddings, predicted_ratings = loaded(model_input)"
      ],
      "metadata": {
        "id": "RbnsSfBvW3KP"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_ratings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sqbv5ShoXeBy",
        "outputId": "f83aac4a-4a8b-444f-ff5f-4a034fc30a0e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5389, 1), dtype=float32, numpy=\n",
              "array([[3.8308444],\n",
              "       [3.1783068],\n",
              "       [3.541618 ],\n",
              "       ...,\n",
              "       [3.5341933],\n",
              "       [3.481803 ],\n",
              "       [3.5044954]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recommended_items = tf.gather(ratings['movieTitle'].unique(), tf.squeeze(tf.argsort(predicted_ratings, axis=0, direction='DESCENDING')))\n",
        "recommended_items"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHxXTIocXfTg",
        "outputId": "d7394192-0ac2-44f9-ad2e-1e933c365397"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5389,), dtype=string, numpy=\n",
              "array([b'Kiss Me, Guido (1997)', b'Billy Elliot (2000)',\n",
              "       b'Oklahoma! (1955)', ..., b'Keeping the Faith (2000)',\n",
              "       b'Primal Fear (1996)', b'Total Eclipse (1995)'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "qHJJVRPcXv87"
      },
      "outputs": [],
      "source": [
        "movie_recommender = tfrs.layers.factorized_top_k.BruteForce(loaded.movie_model, k=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e25fc677-54d9-48c2-ee9c-ce8010a00d6f",
        "id": "rmMumew2Xv88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x7fb9844b3640>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "movie_recommender.index_from_dataset(\n",
        "    movie_dataset.batch(100).map(lambda title: (title, loaded.movie_model(title))))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get some recommendations.\n",
        "_, titles2 = movie_recommender(tf.constant([\"Freaky Friday (2003)\"]), k=25)\n",
        "print(f\"Top 3 recommendations for movie 42: {titles2[:,:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5gXNVmfYH37",
        "outputId": "2a404e99-a292-4370-b2aa-753b01cf34c2"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 recommendations for movie 42: [[b'Ishtar (1987)' b'Christmas Story, A (1983)' b'15 Minutes (2001)'\n",
            "  b\"Hard Day's Night, A (1964)\" b'Places in the Heart (1984)'\n",
            "  b'Toys (1992)' b'Deep Impact (1998)' b'Mrs. Dalloway (1997)'\n",
            "  b'Two Jakes, The (1990)' b'American Ninja (1985)']]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "zCxQ1CZcO2wh",
        "P-HG9ufLVzQI",
        "i3hBkBhwWYV1",
        "Rr7AdTL42RtQ",
        "Q3dGH_I7A_ZO",
        "0Cde_qVN3P1T"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}